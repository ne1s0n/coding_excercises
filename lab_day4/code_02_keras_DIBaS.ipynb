{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "code_02_keras_DIBaS.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ez1PzMW0JwaV"
      },
      "source": [
        "# Foreword\n",
        "The original DIBaS bacterial dataset is available here: http://misztal.edu.pl/software/databases/dibas/\n",
        "\n",
        "We took a subset (five species out of the 33 available), reduced the size of each image (which are now 800 pixels wide) and changed the encoding from .tif to .png. Moreover, we pre-selected a train/test set split, and created a proper folder structure. The final result is [available here](https://raw.githubusercontent.com/ne1s0n/coding_excercises/master/data/dibas_cell_db/dibas_cell_db.zip) (zip file, 72 MB)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pt5MjMC7OpWF"
      },
      "source": [
        "# Assignment\n",
        "\n",
        "Build a multiclass classifier on (a subset of) the DIBaS bacterial dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XwA-hhNn4h6v"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qjEyLHVc4mrL"
      },
      "source": [
        "#where to find the data\n",
        "data_url = 'https://raw.githubusercontent.com/ne1s0n/coding_excercises/master/data/dibas_cell_db/dibas_cell_db.zip'\n",
        "\n",
        "#where to download the compressed data\n",
        "data_root = '/content/data/'\n",
        "\n",
        "#where the images will actually be found\n",
        "base_dir = data_root + 'dibas_cell_db/'\n",
        "\n",
        "#image size (after reshaping)\n",
        "image_shape = (224, 224)\n",
        "\n",
        "#size for mini-batches\n",
        "batch_size = 20"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lYvZO1itO--m"
      },
      "source": [
        "# Data\n",
        "\n",
        "If the data is not here we download it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vhC_pg3yPx_7",
        "outputId": "b8ddf651-06b9-4bca-be96-4e8b2afac770",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "import os\n",
        "import glob\n",
        "import requests\n",
        "import zipfile\n",
        "\n",
        "#this are derived folders\n",
        "train_dir = base_dir + 'train/'\n",
        "val_dir = base_dir + 'test/'\n",
        "\n",
        "#these two lists should contain the full paths of all train and test images\n",
        "train_filenames = glob.glob(train_dir + '*/*')\n",
        "val_filenames   = glob.glob(val_dir + '*/*')\n",
        "\n",
        "#let's check that we actually have the data\n",
        "if len(train_filenames) == 0 or len(val_filenames) == 0:\n",
        "  #either the data was never downloaded or something bad happened\n",
        "  #in any case, we donwload and unzip everything\n",
        "\n",
        "  #room for data\n",
        "  os.makedirs(data_root, exist_ok=True)\n",
        "\n",
        "  #downloading\n",
        "  r = requests.get(data_url)\n",
        "  open(data_root + 'local_archive.zip', 'wb').write(r.content)\n",
        "\n",
        "  #unpacking\n",
        "  z = zipfile.ZipFile(data_root + 'local_archive.zip')\n",
        "  z.extractall(path = data_root)\n",
        "\n",
        "  #at this point data is there, we are ready to get the list of files\n",
        "  train_filenames = glob.glob(base_dir + 'train/*/*')\n",
        "  val_filenames   = glob.glob(base_dir + 'test/*/*')\n",
        "\n",
        "#whatever the original case, at this point we have the files\n",
        "print('Available images for train: ' + str(len(train_filenames)))\n",
        "print('Available images for validation: ' + str(len(val_filenames)))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Available images for train: 89\n",
            "Available images for validation: 20\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34ZPsntnRkcv"
      },
      "source": [
        "# Data generators"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQRnDgp2RlwQ",
        "outputId": "1b4069f8-b3bb-488b-b311-34d3ffe47d7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Data generators\n",
        "train_datagen = ImageDataGenerator(\n",
        "      rescale=1./255,\n",
        "      #bacteria can be upside-down, left-right \n",
        "      #and still being bacteria\n",
        "      horizontal_flip=True,\n",
        "      vertical_flip=True,\n",
        "      \n",
        "      #high rotation values introduce artifacts in the filled\n",
        "      #triangles. Let's keep this low\n",
        "      rotation_range=10,\n",
        "\n",
        "      #conservative parameters, just to meddle a little with\n",
        "      #the possibilities\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      fill_mode='nearest')\n",
        "\n",
        "# Note that the validation data should not be augmented!\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "#filling the generators\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        # This is the target directory\n",
        "        train_dir,\n",
        "        # All images will be resized to image_shape\n",
        "        target_size=image_shape,\n",
        "        batch_size=batch_size,\n",
        "        # Since we use categorical_crossentropy loss, we need categorical labels\n",
        "        class_mode='categorical')\n",
        "\n",
        "# batch_size can be 1 or any factor of test dataset size to ensure that test \n",
        "#dataset is sampled just once, i.e., no data is left out\n",
        "val_generator = val_datagen.flow_from_directory(\n",
        "        val_dir,\n",
        "        target_size=image_shape,\n",
        "        batch_size=5,\n",
        "        class_mode='categorical')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 89 images belonging to 5 classes.\n",
            "Found 20 images belonging to 5 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "akIRfbcMT7jV"
      },
      "source": [
        "# Transfer learning: Resnet50"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_rHWKVKPT-eM"
      },
      "source": [
        "## Get the architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WRAWZJEDSh_i",
        "outputId": "0788311f-18c0-41b8-8d72-aa390f91d51b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "#https://keras.io/api/applications/resnet/#resnet50-function\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "\n",
        "#downloading the net and its weights trained on imagenet dataset\n",
        "my_resnet = ResNet50(weights='imagenet', include_top=False, input_shape=(image_shape[0], image_shape[1], 3))\n",
        "print(\"my_resnet has \" + str(len(my_resnet.layers)) + \" layers\")\n",
        "\n",
        "#it's already the default value, but we set it anyway to \n",
        "#make clear we are not going to train the whole thing\n",
        "my_resnet.trainable = False"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94773248/94765736 [==============================] - 1s 0us/step\n",
            "my_resnet has 175 layers\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQ33rmzyVuFp"
      },
      "source": [
        "## Add the trainable top layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7yO8h3SVB65"
      },
      "source": [
        "from keras import models, layers\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(my_resnet)\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(units=5, activation='softmax'))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ohiLJf7ZWK8G"
      },
      "source": [
        "## Take a look at the network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eleyxWT1WNTa",
        "outputId": "e4eb8aee-d7f6-45a0-f9f7-35dec8b39620",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        }
      },
      "source": [
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "resnet50 (Functional)        (None, 7, 7, 2048)        23587712  \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 100352)            0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 5)                 501765    \n",
            "=================================================================\n",
            "Total params: 24,089,477\n",
            "Trainable params: 501,765\n",
            "Non-trainable params: 23,587,712\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eydSBWqhWP3_"
      },
      "source": [
        "#brave people will look into resnet50\n",
        "#print(my_resnet.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KjcL43lyXLP2"
      },
      "source": [
        "## Model compile"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7SZVe8nsWf1X"
      },
      "source": [
        "from keras import optimizers\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "\n",
        "# Model compile / fit\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='Adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# early stopping: https://keras.io/callbacks/#earlystopping\n",
        "#es = EarlyStopping(monitor='loss', mode='min', min_delta=0.001, verbose=1, patience=40, restore_best_weights=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='loss', mode='min', factor=0.9, patience=15, min_lr=1e-20, verbose=1, cooldown=3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E00ypj6tgmxv"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_foZ6HwqXnug"
      },
      "source": [
        "## Model fit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U8A40nO7Xpbp",
        "outputId": "304dd120-e63a-40ff-9113-d9b835c2b254",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history = model.fit(\n",
        "      train_generator,\n",
        "      #steps_per_epoch=round(ntrain/batch_size,0),\n",
        "      epochs=50,\n",
        "      validation_data=val_generator,\n",
        "      #validation_steps=20, #50\n",
        "      #validation_steps=round(nval/batch_size,0),\n",
        "      #callbacks=[es, reduce_lr],\n",
        "      callbacks=[reduce_lr],\n",
        "      verbose=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "5/5 - 4s - loss: 10.9098 - accuracy: 0.1011 - val_loss: 8.0347 - val_accuracy: 0.2000\n",
            "Epoch 2/50\n",
            "5/5 - 3s - loss: 7.7760 - accuracy: 0.1798 - val_loss: 8.0556 - val_accuracy: 0.4000\n",
            "Epoch 3/50\n",
            "5/5 - 3s - loss: 6.1489 - accuracy: 0.4382 - val_loss: 3.5873 - val_accuracy: 0.4000\n",
            "Epoch 4/50\n",
            "5/5 - 3s - loss: 2.8957 - accuracy: 0.3933 - val_loss: 3.9429 - val_accuracy: 0.5000\n",
            "Epoch 5/50\n",
            "5/5 - 3s - loss: 3.0133 - accuracy: 0.5056 - val_loss: 1.4495 - val_accuracy: 0.6000\n",
            "Epoch 6/50\n",
            "5/5 - 3s - loss: 1.7444 - accuracy: 0.4607 - val_loss: 1.7475 - val_accuracy: 0.6000\n",
            "Epoch 7/50\n",
            "5/5 - 3s - loss: 1.2730 - accuracy: 0.5730 - val_loss: 0.8499 - val_accuracy: 0.4500\n",
            "Epoch 8/50\n",
            "5/5 - 3s - loss: 0.8191 - accuracy: 0.6067 - val_loss: 0.6693 - val_accuracy: 0.7000\n",
            "Epoch 9/50\n",
            "5/5 - 3s - loss: 0.5691 - accuracy: 0.7865 - val_loss: 0.4334 - val_accuracy: 0.8000\n",
            "Epoch 10/50\n",
            "5/5 - 3s - loss: 0.4942 - accuracy: 0.8202 - val_loss: 0.4665 - val_accuracy: 0.8000\n",
            "Epoch 11/50\n",
            "5/5 - 3s - loss: 0.5728 - accuracy: 0.8090 - val_loss: 0.5611 - val_accuracy: 0.6000\n",
            "Epoch 12/50\n",
            "5/5 - 3s - loss: 0.5890 - accuracy: 0.7191 - val_loss: 0.4226 - val_accuracy: 0.9500\n",
            "Epoch 13/50\n",
            "5/5 - 3s - loss: 0.6566 - accuracy: 0.6629 - val_loss: 0.4216 - val_accuracy: 0.8000\n",
            "Epoch 14/50\n",
            "5/5 - 3s - loss: 0.5278 - accuracy: 0.7528 - val_loss: 0.5131 - val_accuracy: 0.7000\n",
            "Epoch 15/50\n",
            "5/5 - 3s - loss: 0.4473 - accuracy: 0.8427 - val_loss: 0.5386 - val_accuracy: 0.6000\n",
            "Epoch 16/50\n",
            "5/5 - 3s - loss: 0.5089 - accuracy: 0.7416 - val_loss: 0.4600 - val_accuracy: 0.8000\n",
            "Epoch 17/50\n",
            "5/5 - 3s - loss: 0.6616 - accuracy: 0.7191 - val_loss: 0.6157 - val_accuracy: 0.7000\n",
            "Epoch 18/50\n",
            "5/5 - 3s - loss: 0.7751 - accuracy: 0.6517 - val_loss: 0.7324 - val_accuracy: 0.7000\n",
            "Epoch 19/50\n",
            "5/5 - 3s - loss: 0.7478 - accuracy: 0.7079 - val_loss: 0.5495 - val_accuracy: 0.6000\n",
            "Epoch 20/50\n",
            "5/5 - 3s - loss: 0.5500 - accuracy: 0.7528 - val_loss: 0.7924 - val_accuracy: 0.7000\n",
            "Epoch 21/50\n",
            "5/5 - 3s - loss: 0.4886 - accuracy: 0.8090 - val_loss: 0.6099 - val_accuracy: 0.7500\n",
            "Epoch 22/50\n",
            "5/5 - 3s - loss: 0.5317 - accuracy: 0.8090 - val_loss: 0.4325 - val_accuracy: 0.8000\n",
            "Epoch 23/50\n",
            "5/5 - 3s - loss: 0.4694 - accuracy: 0.7978 - val_loss: 0.3869 - val_accuracy: 0.9000\n",
            "Epoch 24/50\n",
            "5/5 - 3s - loss: 0.3813 - accuracy: 0.8539 - val_loss: 0.3051 - val_accuracy: 0.9000\n",
            "Epoch 25/50\n",
            "5/5 - 3s - loss: 0.3697 - accuracy: 0.8989 - val_loss: 0.3580 - val_accuracy: 0.9000\n",
            "Epoch 26/50\n",
            "5/5 - 3s - loss: 0.4319 - accuracy: 0.8764 - val_loss: 0.5403 - val_accuracy: 0.6500\n",
            "Epoch 27/50\n",
            "5/5 - 3s - loss: 0.5420 - accuracy: 0.7303 - val_loss: 0.4593 - val_accuracy: 0.6500\n",
            "Epoch 28/50\n",
            "5/5 - 3s - loss: 0.4648 - accuracy: 0.8090 - val_loss: 0.5498 - val_accuracy: 0.7000\n",
            "Epoch 29/50\n",
            "5/5 - 3s - loss: 0.6228 - accuracy: 0.7640 - val_loss: 0.8043 - val_accuracy: 0.6000\n",
            "Epoch 30/50\n",
            "5/5 - 3s - loss: 0.5028 - accuracy: 0.7978 - val_loss: 0.4049 - val_accuracy: 0.8000\n",
            "Epoch 31/50\n",
            "5/5 - 3s - loss: 0.4374 - accuracy: 0.7978 - val_loss: 0.6667 - val_accuracy: 0.7000\n",
            "Epoch 32/50\n",
            "5/5 - 3s - loss: 0.5154 - accuracy: 0.7865 - val_loss: 0.4199 - val_accuracy: 0.8000\n",
            "Epoch 33/50\n",
            "5/5 - 3s - loss: 0.4785 - accuracy: 0.8427 - val_loss: 0.4375 - val_accuracy: 0.6500\n",
            "Epoch 34/50\n",
            "5/5 - 3s - loss: 0.5769 - accuracy: 0.7978 - val_loss: 0.5434 - val_accuracy: 0.7500\n",
            "Epoch 35/50\n",
            "5/5 - 3s - loss: 0.6677 - accuracy: 0.7079 - val_loss: 0.9866 - val_accuracy: 0.6500\n",
            "Epoch 36/50\n",
            "5/5 - 3s - loss: 0.7583 - accuracy: 0.7303 - val_loss: 0.6978 - val_accuracy: 0.7000\n",
            "Epoch 37/50\n",
            "5/5 - 3s - loss: 0.5311 - accuracy: 0.7640 - val_loss: 0.7286 - val_accuracy: 0.6500\n",
            "Epoch 38/50\n",
            "5/5 - 3s - loss: 0.5459 - accuracy: 0.7640 - val_loss: 0.1836 - val_accuracy: 1.0000\n",
            "Epoch 39/50\n",
            "5/5 - 3s - loss: 0.4433 - accuracy: 0.7640 - val_loss: 0.6908 - val_accuracy: 0.7000\n",
            "Epoch 40/50\n",
            "\n",
            "Epoch 00040: ReduceLROnPlateau reducing learning rate to 0.0009000000427477062.\n",
            "5/5 - 3s - loss: 0.6002 - accuracy: 0.6966 - val_loss: 0.3764 - val_accuracy: 0.8000\n",
            "Epoch 41/50\n",
            "5/5 - 3s - loss: 0.4974 - accuracy: 0.7978 - val_loss: 0.3867 - val_accuracy: 0.7000\n",
            "Epoch 42/50\n",
            "5/5 - 3s - loss: 0.5794 - accuracy: 0.7191 - val_loss: 0.4238 - val_accuracy: 0.8000\n",
            "Epoch 43/50\n",
            "5/5 - 3s - loss: 0.4414 - accuracy: 0.8202 - val_loss: 0.4250 - val_accuracy: 0.8000\n",
            "Epoch 44/50\n",
            "5/5 - 3s - loss: 0.4529 - accuracy: 0.8427 - val_loss: 0.2218 - val_accuracy: 0.9000\n",
            "Epoch 45/50\n",
            "5/5 - 3s - loss: 0.3627 - accuracy: 0.8427 - val_loss: 0.5442 - val_accuracy: 0.6500\n",
            "Epoch 46/50\n",
            "5/5 - 3s - loss: 0.4075 - accuracy: 0.8764 - val_loss: 0.6070 - val_accuracy: 0.8000\n",
            "Epoch 47/50\n",
            "5/5 - 3s - loss: 0.4029 - accuracy: 0.8539 - val_loss: 0.6694 - val_accuracy: 0.8000\n",
            "Epoch 48/50\n",
            "5/5 - 3s - loss: 0.5209 - accuracy: 0.8315 - val_loss: 0.4460 - val_accuracy: 0.7000\n",
            "Epoch 49/50\n",
            "5/5 - 3s - loss: 0.3184 - accuracy: 0.9326 - val_loss: 0.1683 - val_accuracy: 1.0000\n",
            "Epoch 50/50\n",
            "5/5 - 3s - loss: 0.2416 - accuracy: 0.9663 - val_loss: 0.3400 - val_accuracy: 0.8500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jD1eJy0-_b6U"
      },
      "source": [
        "# CNN from scratch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qXsmCV6jaZiT"
      },
      "source": [
        "## Define the architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uj9gGOSr_fHU"
      },
      "source": [
        "from keras import models, layers\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten\n",
        "\n",
        "model2 = models.Sequential()\n",
        "model2.add(Conv2D(32, (3, 3), padding=\"same\", activation=\"relu\", input_shape=(image_shape[0], image_shape[1], 3)))\n",
        "model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model2.add(Conv2D(64, (3, 3), padding=\"same\", activation=\"relu\"))\n",
        "model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model2.add(Conv2D(128, (3, 3), padding=\"same\", activation=\"relu\"))\n",
        "model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model2.add(layers.Flatten())\n",
        "model2.add(layers.Dense(units=5, activation='softmax'))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CID1Ksq-af2R"
      },
      "source": [
        "## Take a look at the network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ao6C8RLUYS9B",
        "outputId": "8f639038-4551-45a3-9072-b366ca6e093b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        }
      },
      "source": [
        "print(model2.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 224, 224, 32)      896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 112, 112, 32)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 112, 112, 64)      18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 56, 56, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 56, 56, 128)       73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 28, 28, 128)       0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 100352)            0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 5)                 501765    \n",
            "=================================================================\n",
            "Total params: 595,013\n",
            "Trainable params: 595,013\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t4UsEmquawS8"
      },
      "source": [
        "## Model compile"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WC8Bb5hBaiaX"
      },
      "source": [
        "model2.compile(loss='categorical_crossentropy',\n",
        "              optimizer='Adam',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ng29b1vTa14m"
      },
      "source": [
        "## Model fit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P7tQe9uDazRx",
        "outputId": "7c35e1de-7d1e-45f7-e6c9-3c55baacef4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history2 = model2.fit(\n",
        "      train_generator,\n",
        "      #steps_per_epoch=round(ntrain/batch_size,0),\n",
        "      epochs=50,\n",
        "      validation_data=val_generator,\n",
        "      #validation_steps=20, #50\n",
        "      #validation_steps=round(nval/batch_size,0),\n",
        "      #callbacks=[es, reduce_lr],\n",
        "      verbose=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "5/5 - 3s - loss: 2.2789 - accuracy: 0.2135 - val_loss: 1.6747 - val_accuracy: 0.3500\n",
            "Epoch 2/50\n",
            "5/5 - 3s - loss: 1.6363 - accuracy: 0.2921 - val_loss: 1.5655 - val_accuracy: 0.2000\n",
            "Epoch 3/50\n",
            "5/5 - 3s - loss: 1.5535 - accuracy: 0.2022 - val_loss: 1.4552 - val_accuracy: 0.4000\n",
            "Epoch 4/50\n",
            "5/5 - 3s - loss: 1.3951 - accuracy: 0.4157 - val_loss: 1.1937 - val_accuracy: 0.6500\n",
            "Epoch 5/50\n",
            "5/5 - 3s - loss: 1.2531 - accuracy: 0.4157 - val_loss: 1.0711 - val_accuracy: 0.5500\n",
            "Epoch 6/50\n",
            "5/5 - 3s - loss: 1.0282 - accuracy: 0.5618 - val_loss: 0.8245 - val_accuracy: 0.8000\n",
            "Epoch 7/50\n",
            "5/5 - 3s - loss: 0.7169 - accuracy: 0.7079 - val_loss: 0.5892 - val_accuracy: 0.7000\n",
            "Epoch 8/50\n",
            "5/5 - 3s - loss: 0.5246 - accuracy: 0.7416 - val_loss: 0.5533 - val_accuracy: 0.6500\n",
            "Epoch 9/50\n",
            "5/5 - 3s - loss: 0.6383 - accuracy: 0.6742 - val_loss: 0.8055 - val_accuracy: 0.6000\n",
            "Epoch 10/50\n",
            "5/5 - 3s - loss: 0.7292 - accuracy: 0.6404 - val_loss: 0.6807 - val_accuracy: 0.6000\n",
            "Epoch 11/50\n",
            "5/5 - 3s - loss: 0.6582 - accuracy: 0.6292 - val_loss: 0.6915 - val_accuracy: 0.6000\n",
            "Epoch 12/50\n",
            "5/5 - 3s - loss: 0.6134 - accuracy: 0.6629 - val_loss: 0.6165 - val_accuracy: 0.6000\n",
            "Epoch 13/50\n",
            "5/5 - 3s - loss: 0.5648 - accuracy: 0.6966 - val_loss: 0.5827 - val_accuracy: 0.6500\n",
            "Epoch 14/50\n",
            "5/5 - 3s - loss: 0.5144 - accuracy: 0.6854 - val_loss: 0.6136 - val_accuracy: 0.6000\n",
            "Epoch 15/50\n",
            "5/5 - 3s - loss: 0.4951 - accuracy: 0.7640 - val_loss: 0.3948 - val_accuracy: 0.8500\n",
            "Epoch 16/50\n",
            "5/5 - 3s - loss: 0.4266 - accuracy: 0.8652 - val_loss: 0.4346 - val_accuracy: 0.8000\n",
            "Epoch 17/50\n",
            "5/5 - 3s - loss: 0.3935 - accuracy: 0.7865 - val_loss: 0.6824 - val_accuracy: 0.6000\n",
            "Epoch 18/50\n",
            "5/5 - 3s - loss: 0.5507 - accuracy: 0.8090 - val_loss: 0.4703 - val_accuracy: 0.7500\n",
            "Epoch 19/50\n",
            "5/5 - 3s - loss: 0.5127 - accuracy: 0.7416 - val_loss: 0.6733 - val_accuracy: 0.7000\n",
            "Epoch 20/50\n",
            "5/5 - 3s - loss: 0.3403 - accuracy: 0.8427 - val_loss: 0.2925 - val_accuracy: 0.9000\n",
            "Epoch 21/50\n",
            "5/5 - 3s - loss: 0.3357 - accuracy: 0.8652 - val_loss: 1.0242 - val_accuracy: 0.6500\n",
            "Epoch 22/50\n",
            "5/5 - 3s - loss: 0.2895 - accuracy: 0.8876 - val_loss: 0.3958 - val_accuracy: 0.7500\n",
            "Epoch 23/50\n",
            "5/5 - 3s - loss: 0.3892 - accuracy: 0.8090 - val_loss: 0.3006 - val_accuracy: 0.8500\n",
            "Epoch 24/50\n",
            "5/5 - 3s - loss: 0.3481 - accuracy: 0.8315 - val_loss: 0.3195 - val_accuracy: 0.9000\n",
            "Epoch 25/50\n",
            "5/5 - 3s - loss: 0.3360 - accuracy: 0.7865 - val_loss: 0.7552 - val_accuracy: 0.8000\n",
            "Epoch 26/50\n",
            "5/5 - 3s - loss: 0.3629 - accuracy: 0.8539 - val_loss: 0.1796 - val_accuracy: 0.9500\n",
            "Epoch 27/50\n",
            "5/5 - 3s - loss: 0.2808 - accuracy: 0.8989 - val_loss: 0.4527 - val_accuracy: 0.7500\n",
            "Epoch 28/50\n",
            "5/5 - 3s - loss: 0.1818 - accuracy: 0.9663 - val_loss: 0.3329 - val_accuracy: 0.8500\n",
            "Epoch 29/50\n",
            "5/5 - 3s - loss: 0.1475 - accuracy: 0.9663 - val_loss: 0.3387 - val_accuracy: 0.9000\n",
            "Epoch 30/50\n",
            "5/5 - 3s - loss: 0.1572 - accuracy: 0.9438 - val_loss: 0.3190 - val_accuracy: 0.8500\n",
            "Epoch 31/50\n",
            "5/5 - 3s - loss: 0.1146 - accuracy: 0.9775 - val_loss: 0.1424 - val_accuracy: 0.9500\n",
            "Epoch 32/50\n",
            "5/5 - 3s - loss: 0.1052 - accuracy: 0.9775 - val_loss: 0.1253 - val_accuracy: 0.9500\n",
            "Epoch 33/50\n",
            "5/5 - 3s - loss: 0.1396 - accuracy: 0.9551 - val_loss: 0.2320 - val_accuracy: 0.9000\n",
            "Epoch 34/50\n",
            "5/5 - 3s - loss: 0.1148 - accuracy: 0.9663 - val_loss: 0.1320 - val_accuracy: 0.9500\n",
            "Epoch 35/50\n",
            "5/5 - 3s - loss: 0.0849 - accuracy: 0.9663 - val_loss: 0.1622 - val_accuracy: 0.9500\n",
            "Epoch 36/50\n",
            "5/5 - 3s - loss: 0.0750 - accuracy: 0.9888 - val_loss: 0.1976 - val_accuracy: 0.9500\n",
            "Epoch 37/50\n",
            "5/5 - 3s - loss: 0.0909 - accuracy: 0.9775 - val_loss: 0.1768 - val_accuracy: 0.9000\n",
            "Epoch 38/50\n",
            "5/5 - 3s - loss: 0.3137 - accuracy: 0.8876 - val_loss: 1.2975 - val_accuracy: 0.6000\n",
            "Epoch 39/50\n",
            "5/5 - 3s - loss: 0.6819 - accuracy: 0.7303 - val_loss: 0.9556 - val_accuracy: 0.5500\n",
            "Epoch 40/50\n",
            "5/5 - 3s - loss: 0.4781 - accuracy: 0.7191 - val_loss: 0.2801 - val_accuracy: 0.8000\n",
            "Epoch 41/50\n",
            "5/5 - 3s - loss: 0.6207 - accuracy: 0.7978 - val_loss: 0.3287 - val_accuracy: 0.8500\n",
            "Epoch 42/50\n",
            "5/5 - 3s - loss: 0.3147 - accuracy: 0.8989 - val_loss: 0.3125 - val_accuracy: 0.9000\n",
            "Epoch 43/50\n",
            "5/5 - 3s - loss: 0.4757 - accuracy: 0.7865 - val_loss: 0.1993 - val_accuracy: 0.9500\n",
            "Epoch 44/50\n",
            "5/5 - 3s - loss: 0.3750 - accuracy: 0.8315 - val_loss: 0.1938 - val_accuracy: 0.9500\n",
            "Epoch 45/50\n",
            "5/5 - 3s - loss: 0.2508 - accuracy: 0.9101 - val_loss: 0.4254 - val_accuracy: 0.8000\n",
            "Epoch 46/50\n",
            "5/5 - 3s - loss: 0.1894 - accuracy: 0.9663 - val_loss: 0.1940 - val_accuracy: 0.9500\n",
            "Epoch 47/50\n",
            "5/5 - 3s - loss: 0.1479 - accuracy: 0.9775 - val_loss: 0.2054 - val_accuracy: 0.9500\n",
            "Epoch 48/50\n",
            "5/5 - 3s - loss: 0.1141 - accuracy: 0.9775 - val_loss: 0.4533 - val_accuracy: 0.8000\n",
            "Epoch 49/50\n",
            "5/5 - 3s - loss: 0.1357 - accuracy: 0.9551 - val_loss: 0.0909 - val_accuracy: 1.0000\n",
            "Epoch 50/50\n",
            "5/5 - 3s - loss: 0.1023 - accuracy: 0.9663 - val_loss: 0.1018 - val_accuracy: 0.9500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tHLOoyu6hIXZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}