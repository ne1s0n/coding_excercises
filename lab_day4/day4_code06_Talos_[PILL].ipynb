{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Foreword\n",
        "\n",
        "In this notebook we show how to use the Talos tool for automatic network optimization (and, in general, hyperparameter tuning). This example uses the breast cancer dataset which we have already seen in the course and is completely self contained. However if you want to further understand what's going on please refer to:\n",
        "\n",
        "* [Talos library official website](https://pypi.org/project/talos/)\n",
        "* [Talos github repository, with examples](https://github.com/autonomio/talos)\n",
        "* [Talos documentation](https://autonomio.github.io/talos/#/README?id=quick-start)"
      ],
      "metadata": {
        "id": "UCAXsNUl8vi6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup(s)"
      ],
      "metadata": {
        "id": "gIsUPNka9iyn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Standard libraries setup"
      ],
      "metadata": {
        "id": "rp0Rk8YU96Qq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LKEvHzQW8oF1"
      },
      "outputs": [],
      "source": [
        "#very common libraries, that we for sure are using\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Talos setup"
      ],
      "metadata": {
        "id": "2VF13QL2-a0J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#making sure talos is installed\n",
        "!pip install talos\n",
        "\n",
        "#importing the library\n",
        "import talos"
      ],
      "metadata": {
        "id": "wYA-0aeu-cbx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Seed setup"
      ],
      "metadata": {
        "id": "OInn7vWK98f4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy.random import seed\n",
        "myseed = 0\n",
        "seed(myseed)\n",
        "tf.random.set_seed(myseed)"
      ],
      "metadata": {
        "id": "bxUUBoWD9_i7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data setup"
      ],
      "metadata": {
        "id": "Gl9Z_VYG-Bsj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#libraries for this block\n",
        "import sklearn.datasets\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "\n",
        "# loading data\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "bcancer = load_breast_cancer()\n",
        "y = bcancer.target\n",
        "X = pd.DataFrame(bcancer.data, columns=bcancer.feature_names)\n",
        "\n",
        "# normalizing\n",
        "X = (X - X.mean())/X.std()"
      ],
      "metadata": {
        "id": "MB-txeIB-DtB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Talos workflow"
      ],
      "metadata": {
        "id": "5r2sb5SC-ETn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hyperparamaters to be explored\n",
        "\n",
        "This part becomes central. We define the space (i.e. the amount of combinations) that we are going to explore."
      ],
      "metadata": {
        "id": "v56QtRoGXFpE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#talos requires a dictionary\n",
        "my_parameters = {\n",
        "    #these hyperparameters need to be optimized\n",
        "    'first_layer': [12, 24, 48],\n",
        "    'second_layer': [12, 24, 48],\n",
        "    'LR' : [0.0001, 0.1, 10]\n",
        "}"
      ],
      "metadata": {
        "id": "-Sp-rgm4XY54"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train function (default, without Talos)\n",
        "\n",
        "We report below a basic function used to train and return a model. It doesn not accept any hyperparameter (all values are hard coded). It will not be used in the example, but it serves as reference for when we integrate Talos."
      ],
      "metadata": {
        "id": "vhPZWn__YAlV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#libraries for this block\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "\n",
        "# a function to declare and train the network. Returns the trained model\n",
        "def train_net_default(x_train, y_train, x_val, y_val):\n",
        "\n",
        "  #this depends on the input data\n",
        "  input_shape = (x_train.shape[1],)\n",
        "\n",
        "  #a simple neural network with two hidden layers\n",
        "  model = Sequential()\n",
        "  model.add(Dense(10, activation='relu'))\n",
        "  model.add(Dense(5, activation='relu'))\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "  #instantiating the optimizer, compiling, training\n",
        "  opt = SGD(learning_rate=0.1)\n",
        "  model.compile(optimizer=opt, loss='binary_crossentropy')\n",
        "  history = model.fit(x=x_train, y=y_train, validation_data=[x_val, y_val],\n",
        "                      epochs=100, verbose=0)\n",
        "\n",
        "  return(model)\n"
      ],
      "metadata": {
        "id": "uKkjC7PgYDTx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train function, with Talos"
      ],
      "metadata": {
        "id": "OMuCzRP5Z8Ok"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# a function to declare and train the network, accepting a dictionary of\n",
        "# hyperparameters. It must return both the trained model and the training history\n",
        "def train_net_talos(x_train, y_train, x_val, y_val, par):\n",
        "\n",
        "  #this depends on the input data\n",
        "  input_shape = (X.shape[1],)\n",
        "\n",
        "  #a simple neural network with two hidden layers\n",
        "  model = Sequential()\n",
        "  model.add(Dense(par['first_layer'], activation='relu'))\n",
        "  model.add(Dense(par['second_layer'], activation='relu'))\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "  #instantiating the optimizer, compiling, training\n",
        "  opt = SGD(learning_rate=par['LR'])\n",
        "  model.compile(optimizer=opt, loss='binary_crossentropy')\n",
        "  history = model.fit(x=x_train, y=y_train, validation_data=[x_val, y_val],\n",
        "                      epochs=100, verbose=0)\n",
        "\n",
        "  #returning both history and model, in that order\n",
        "  return(history, model)"
      ],
      "metadata": {
        "id": "ytf7UD8MZ_u2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Running a Talos \"scan\"\n",
        "\n",
        "In this simple example Talos will check all the available combinations, once."
      ],
      "metadata": {
        "id": "8BhWOmA0dfq1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#note: Talos does not directly support Pandas dataframes. However, it's quite\n",
        "#straightforward to obtain a table using .values\n",
        "t = talos.Scan(x=X.values, y=y, params=my_parameters, model=train_net_talos, experiment_name='breast_cancer')"
      ],
      "metadata": {
        "id": "jJyv0iuZdjGD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We just obtained a Scan object, which contain in the `.data` field information on all the tested combinations."
      ],
      "metadata": {
        "id": "ZmXXnqDg-ItX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(t))\n",
        "print(t.data.shape)"
      ],
      "metadata": {
        "id": "mcr8hyYE97CK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Taking a look at the results"
      ],
      "metadata": {
        "id": "4tcfJBfB-Yp3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t.data"
      ],
      "metadata": {
        "id": "9qbCe6-Meci0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extracting the best configuration"
      ],
      "metadata": {
        "id": "Psbagum5-gkR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#a local copy, for easier notation\n",
        "df = t.data\n",
        "\n",
        "#printing the row with lowest validation loss\n",
        "df[df.val_loss == df.val_loss.min()]"
      ],
      "metadata": {
        "id": "GtTwdrnV9xSR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extracting the best performing model"
      ],
      "metadata": {
        "id": "3u1oOI4q_YYg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#I need to specify what is the criterion (i.e. the metric) used to define the \"best\" model.\n",
        "#Moreover, \"asc\" has to be True for the case where the metric is something to be minimized.\n",
        "best_model = t.best_model(metric='val_loss', asc=True)\n",
        "print(type(best_model))"
      ],
      "metadata": {
        "id": "pVjFkH49_bE6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Further steps\n",
        "\n",
        "The code above is a **very** minimal example and works as a starting point. Stuff to consider:\n",
        "\n",
        "* each combination of hyperparameter is trained once, with a 70/30 default split. Using `.evaluate_models()` it's possible to do a proper k-fold crossvalidation (see [scan documentation](https://autonomio.github.io/talos/#/Scan), search \"evaluate_models\")\n",
        "* the default approach of trying all the combinations can become unfeasible very quickly. The `Scan` function supports several policies for sampling a subset of the hyperparameter space. See the [Towardsdatascience's tutorial](https://towardsdatascience.com/tune-the-hyperparameters-of-your-deep-learning-networks-in-python-using-keras-and-talos-2a2a38c5ac31) for a more in-depth example"
      ],
      "metadata": {
        "id": "miy4ArJAAF7d"
      }
    }
  ]
}