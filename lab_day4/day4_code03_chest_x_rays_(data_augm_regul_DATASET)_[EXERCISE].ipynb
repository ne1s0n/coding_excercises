{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"a-TykfLxN6_L"},"source":["# Chest X ray problem\n","\n","Binary classification problem, we are asked to classify chest X rays from patients and tell which are sick and which are healty.\n","\n","The dataset is deposited [here](https://www.kaggle.com/paultimothymooney/chest-xray-pneumonia).\n","\n","For a \"heavy guns\" solution for this problem (with data augmentation, learning rate decay, memory optimization and other neat advanced stuff) see [here](https://www.kaggle.com/amyjang/tensorflow-pneumonia-classification-on-x-rays)"]},{"cell_type":"markdown","metadata":{"id":"066Hk1V5_AP2"},"source":["# Config\n","\n","These constants are given for the exercise."]},{"cell_type":"code","metadata":{"id":"NiaFDmq3-2qq"},"source":["#where the data are stored\n","data_url = 'http://www.jackdellequerce.com/data/reduced_chest_xray.zip'\n","\n","#where to place the data\n","download_target_imgs = '/content/data/'\n","base_dir = download_target_imgs + 'reduced_chest_xray/'\n","\n","#Keras constants\n","BATCH_SIZE = 20\n","IMAGE_SIZE = [128, 128]\n","IMAGE_SHAPE = (IMAGE_SIZE[0], IMAGE_SIZE[1] , 3)\n","EPOCHS = 10"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kkcf_AVX_l9D"},"source":["# Data setup\n","\n","The following code ensures that the images are present in `base_dir` folder. If the data is not there it is downloaded and unpacked."]},{"cell_type":"code","metadata":{"id":"OWSI4K5-_nG1"},"source":["import glob     #for checking dir content\n","import os       #for dir creation\n","import requests #for data download\n","import zipfile  #for unpacking zipped files\n","\n","#these two lists should contain the full paths of all train and test images\n","train_filenames = glob.glob(base_dir + 'train/*/*')\n","validation_filenames   = glob.glob(base_dir + 'test/*/*')\n","\n","#let's check that we actually have the data\n","if len(train_filenames) == 0 or len(validation_filenames) == 0:\n","  #either the data was never downloaded or something bad happened\n","  #in any case, we donwload and unzip everything\n","\n","  #room for data\n","  os.makedirs(download_target_imgs, exist_ok=True)\n","\n","  #downloading\n","  r = requests.get(data_url)\n","  open(download_target_imgs + 'local_archive.zip', 'wb').write(r.content)\n","\n","  #unpacking\n","  z = zipfile.ZipFile(download_target_imgs + 'local_archive.zip')\n","  z.extractall(path = download_target_imgs)\n","\n","  #at this point data is there, we are ready to get the list of files\n","  train_filenames = glob.glob(base_dir + 'train/*/*')\n","  validation_filenames   = glob.glob(base_dir + 'test/*/*')\n","\n","#whatever the original case, at this point we have the files\n","print('Available images for train: ' + str(len(train_filenames)))\n","print('Available images for validation: ' + str(len(validation_filenames)))\n","\n","#let's store the folder names, for future use\n","train_dir = os.path.join(base_dir, 'train')\n","validation_dir = os.path.join(base_dir, 'test')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lVybJWNWBKdZ"},"source":["# Data loading via tf.data.dataset\n","\n","We are going to use [datasets](https://www.tensorflow.org/datasets) objects for loading the images from the local memory. This class substituted substituted [ImageDataGenerator](https://keras.io/api/preprocessing/image/#imagedatagenerator-class), which is slowly going to be deprecated and removed from code.\n","\n","`tf.data.Dataset` is TensorFlow’s efficient, composable pipeline for input data.\n","You can think of it as a streaming sequence of (image, label) pairs that supports:\n","\n","- Automatic prefetching and parallel I/O\n","- On-the-fly preprocessing\n","- Shuffling, batching, and repeating\n","- GPU/TPU-optimized pipelines\n","\n","When working with images it is important to rescale them in from the 0-255 range to 0-1, as explained in details [here](https://github.com/Arsey/keras-transfer-learning-for-oxford102/issues/1\n",").\n","\n","**ASSIGNMENT**: In the next snippet you need to import `tf.data.Dataset` and then declare two objects named `train_ds` and `validation_ds`. To do so we are going to use the utility function `image_dataset_from_directory()` part of the [tf.keras.utils](https://www.tensorflow.org/api_docs/python/tf/keras/utils) package, Hint: go to the package help, look for the function signature and see the labels. We'll need to specify at least the folder where to find the images, plus some other info.\n","\n","**NOTE**: parameter `batch_size` on train dataset influences the amount of memory required. Usually the bigger the better, but the system can easily become overloaded."]},{"cell_type":"code","metadata":{"id":"8A8XsNRC_xZF"},"source":["### YOUR CODE HERE ###\n","######################"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Image preprocessing (rescaling)\n","\n","Images need to be rescaled in the [0,1] range. Originally images are grayscale in the [0-255] range, so we need a rescaling factor of 1.0/255<br>\n","The \".0\" part is important so python will do a floating point division and not an integer division, in fact:\n","\n","- 1.0/255 → 0,003921569\n","- 1/255 → 0\n","\n","For this snipped you'll need a two step solution:\n","\n","1. define a `rescale_image` function that receives an image and a label. The image you'll rescale as discussed above, the label will stay the same. The new tuple (rescaled_image, label) will be returned by the funciton\n","2. invoke for both `train_ds` and `val_ds` the [.map()](https://www.tensorflow.org/api_docs/python/tf/data/Dataset#map) method, which applies a function to all elements of the dataset. You'll pass `rescale_image` to it. Keep in mind that .map() \"returns a new dataset containing the transformed elements\", so you'll need to reassign back to `train_ds` and `val_ds`\n"],"metadata":{"id":"o4ZK8o7Ie-jq"}},{"cell_type":"code","source":["### YOUR CODE HERE ###\n","######################"],"metadata":{"id":"sBX0IfM6fFn_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jh56-KGTbMpu"},"source":["# Data augmentation\n","\n","Do some data augmentation telling `train_datagen` to do horizontal flips. To do so we need to use the `RandomFlip` layer from the standard [keras.layers](https://www.tensorflow.org/api_docs/python/tf/keras/layers) module.\n","\n","Here's the steps:\n","\n","1. declare a new object of `Sequential` type, containing a single `Randomflip` layer\n","2. define an `augment_images(image, label)` function, which internally applies\n","the model defined in the step above to the image. This function returns a tuple with (augmented_image, label)\n","3. invoke for `train_ds` the [.map()](https://www.tensorflow.org/api_docs/python/tf/data/Dataset#map) method, which applies a function to all elements of the dataset. You'll pass `augment_images` to it. Keep in mind that .map() \"returns a new dataset containing the transformed elements\", so you'll need to reassign back to `train_ds`\n","\n","**Important**: never do data augmentation on the validation set. Can you guess what the consequences would be?\n"]},{"cell_type":"code","source":["### YOUR CODE HERE ###\n","######################"],"metadata":{"id":"QYaloOfDYkVr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VsJe3QdjFQFg"},"source":["# Architecture - Define\n","\n","It's now time to define an architecture. You'll use the usual [Sequential model](https://keras.io/guides/sequential_model/).\n","\n","**ASSIGNMENT**: Declare a model with the following layers:\n","\n","1. [Conv2D layer](https://keras.io/api/layers/convolution_layers/convolution2d/), 32 nodes, 3x3 kernel, \"same\" padding, \"relu\" activation\n","2. [MaxPooling2D layer](https://keras.io/api/layers/pooling_layers/max_pooling2d/), 2x2 pool size\n","3. another Conv2D layer, this time 64 nodes, everything else same as above\n","4. another MaxPooling2D, same as above\n","5. [Flatten layer](https://keras.io/api/layers/reshaping_layers/flatten/)\n","6. [Dense layer](https://keras.io/api/layers/core_layers/dense/), used as output, \"sigmoid\" activation function. Can you guess the number of nodes?\n","\n","The first layer is the input layer and requires also an `input_shape`, which you find in the `IMAGE_SHAPE` constant you declared above.\n","\n","**OPTIONAL ASSIGNMENT** put a Dropout layer after the first MaxPooling2D with a rate of 0.2. Do you need to change something else in the code?\n"]},{"cell_type":"code","metadata":{"id":"824q9YfpCyvz"},"source":["from keras.models import Sequential\n","from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Input\n","from keras.layers import Dropout\n","\n","#let's declare an empty model\n","model = Sequential()\n","\n","### YOUR CODE HERE ###\n","######################"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eko67WVQFYvR"},"source":["# Architecture - Take a look\n","\n","You have defined the architecture, it's time to take a look at your work. Keras offers two options:\n","\n","* the [.summary()](https://keras.io/api/models/model/#summary-method) method built-in your model object\n","* [plot_model()](https://keras.io/api/utils/model_plotting_utils/#plotmodel-function) function from `keras.utils.vis_utils` package.\n","\n","**ASSIGNMENT** invoke either `.build()` (easy) or `plot_model()` (more complicated), take a look inside your model and verify that everything is as expected in terms of number of layers, output size and so forth."]},{"cell_type":"code","metadata":{"id":"Bd0J3rW9FaN8"},"source":["### YOUR CODE HERE ###\n","######################"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hv6BvycrG16o"},"source":["# Architecture - Compile\n","\n","So far you have defined the topology of your network, it's now time to specify how you are going to measure its performance.\n","\n","**ASSIGNMENT** invoke the [.compile()](https://keras.io/api/models/model_training_apis/#compile-method)  method for your model, specifying the [loss function](https://keras.io/api/losses/) (we are doing binary classification, so 'binary_crossentropy' is the standard choice)\n","\n","**OPTIONAL ASSIGNMENT 1**: ask keras to keep track of an extra metric, 'accuracy'. Keep in mind that `.compile()` expects a list of strings when specifying metrics, even if only one element is present.\n","\n","**OPTIONAL ASSIGNMENT 2**: default optimizer is [RMSprop](https://keras.io/api/optimizers/rmsprop/), with a default learning rate of 0.001. Declare the optimizer so that the used learning rate is 0.00002. (Tip: you'll need to import RMSprop from tensorflow...)"]},{"cell_type":"code","metadata":{"id":"iKB2yjhDG4hy"},"source":["### YOUR CODE HERE ###\n","######################\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KmZxgrc2GNTE"},"source":["# Train\n","\n","It's finally time to train your model using the [.fit()](https://keras.io/api/models/model_training_apis/#fit-method) method.\n","\n","**ASSIGNMENT**: train your model speifying that:\n","\n","* your train data (argument `x`) is in `train_ds`\n","* your validation data (argument `validation_data`) is in `validation_ds`\n","* the desider number of epochs (argument `epochs`) is in the declared constant `EPOCHS`\n","* `verbose` level = 2 so that we can take a look at what's happening\n","\n","The returned object should go in a new variable called `train_log`"]},{"cell_type":"code","metadata":{"id":"pTGAZgNkGFJt"},"source":["### YOUR CODE HERE ###\n","######################"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yltaSPLFLV0X"},"source":["# Support function for plotting metrics\n","\n","The following function is a small utility that allows for plotting loss and all the metrics returned by a `.fit()` call. Just execute the snippet so that the function is declared. Or, if you are curious, take a look at the code :)"]},{"cell_type":"code","metadata":{"id":"d57KmwRHKpN8"},"source":["import matplotlib.pyplot as plt\n","\n","def plot_loss_history(h, title):\n","  for metric in h.history.keys():\n","    #ignoring metrics on validation set, which are implied when\n","    #plotting on training set\n","    if metric.startswith('val_'):\n","      continue\n","\n","    #if we get here we found a metric on the training set,\n","    #let's plot it\n","    plt.plot(h.history[metric], label = \"Train set\")\n","    plt.plot(h.history[\"val_\" + metric], label = \"Validation set\")\n","    plt.xlabel('Epochs')\n","    plt.title(title + ' - ' + metric)\n","    plt.legend()\n","    plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QHr7PqtFLd0E"},"source":["# Plotting your model performances\n","\n","As a final step, plot loss (and metrics, if present) of your training.\n","\n","**ASSIGNMENT**: use the `plot_loss_history()` you just declared to plot the evolution of your training. What consideration can you do?"]},{"cell_type":"code","metadata":{"id":"LHMOMfuKLRd_"},"source":["### YOUR CODE HERE ###\n","######################"],"execution_count":null,"outputs":[]}]}