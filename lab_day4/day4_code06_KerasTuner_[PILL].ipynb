{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# KerasTuner\n",
        "\n",
        "KerasTuner is an easy-to-use, scalable hyperparameter optimization framework that solves the pain points of hyperparameter search. KerasTuner comes with Bayesian Optimization, Hyperband, and Random Search algorithms built-in, and is also designed to be easy for researchers to extend in order to experiment with new search algorithms.\n",
        "In this notebook we show how to use the **KerasTuner** for automatic network optimization (and, in general, hyperparameter tuning). This example uses the breast cancer dataset which we have already seen in the course and is completely self contained. However if you want to further understand what's going on please refer to:\n",
        "\n",
        "* [Official website](https://keras.io/keras_tuner/)\n",
        "* [Tutorial at Tensorflow](https://www.tensorflow.org/tutorials/keras/keras_tuner)\n",
        "* [Tutorial at medium.com](https://haneulkim.medium.com/hyperparameter-tuning-with-keras-tuner-full-tutorial-f8128397e857)"
      ],
      "metadata": {
        "id": "UCAXsNUl8vi6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup(s)"
      ],
      "metadata": {
        "id": "gIsUPNka9iyn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Standard libraries setup"
      ],
      "metadata": {
        "id": "rp0Rk8YU96Qq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "LKEvHzQW8oF1"
      },
      "outputs": [],
      "source": [
        "#very common libraries, that we for sure are using\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Talos setup"
      ],
      "metadata": {
        "id": "2VF13QL2-a0J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#making sure KerasTuner is installed.\n",
        "!pip install -q -U keras-tuner"
      ],
      "metadata": {
        "id": "wYA-0aeu-cbx",
        "collapsed": true
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras_tuner as kt"
      ],
      "metadata": {
        "id": "dn37MY_MA0cd"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Seed setup"
      ],
      "metadata": {
        "id": "OInn7vWK98f4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#resetting the seeds\n",
        "!wget -O support_code.py https://raw.githubusercontent.com/ne1s0n/coding_excercises/master/lab_day1/support_code.py\n",
        "%run support_code.py\n",
        "n1 = 0\n",
        "reset_random_seeds(n1)"
      ],
      "metadata": {
        "id": "bxUUBoWD9_i7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6251bf54-87bc-4dc2-9aec-9409a4156ecd"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-10-30 12:41:53--  https://raw.githubusercontent.com/ne1s0n/coding_excercises/master/lab_day1/support_code.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6242 (6.1K) [text/plain]\n",
            "Saving to: ‘support_code.py’\n",
            "\n",
            "support_code.py     100%[===================>]   6.10K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-10-30 12:41:53 (85.3 MB/s) - ‘support_code.py’ saved [6242/6242]\n",
            "\n",
            "Import all libraries: yes\n",
            "importing libraries\n",
            "Defining functions\n",
            "DONE!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data setup"
      ],
      "metadata": {
        "id": "Gl9Z_VYG-Bsj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#libraries for this block\n",
        "import sklearn.datasets\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "\n",
        "# loading data\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "bcancer = load_breast_cancer()\n",
        "y = bcancer.target\n",
        "X = pd.DataFrame(bcancer.data, columns=bcancer.feature_names)\n",
        "\n",
        "# normalizing\n",
        "X = (X - X.mean())/X.std()"
      ],
      "metadata": {
        "id": "MB-txeIB-DtB"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#declaring a sss object\n",
        "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2)\n",
        "\n",
        "#sss.split() returns two iterables over the two pieces of data\n",
        "for train_index, val_index in sss.split(X=X, y=y):\n",
        "  x_train = X.iloc[train_index, :]\n",
        "  x_val   = X.iloc[val_index, :]\n",
        "\n",
        "  y_train = y[train_index]\n",
        "  y_val   = y[val_index]"
      ],
      "metadata": {
        "id": "eWBINuoXEaAy"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# KerasTuner workflow"
      ],
      "metadata": {
        "id": "5r2sb5SC-ETn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define the (hyper)model\n",
        "\n",
        "When you build a model for the tuning of the hyperparameters, you also define the **hyperparameter search space** in addition to the model architecture.\n",
        "The model you set up for fine-tuning is called a **hypermodel**.\n",
        "\n",
        "With **KerasTuner**, you can define a hypermodel through two approaches:\n",
        "\n",
        "- by using a **model builder function**\n",
        "- by subclassing the **HyperModel class** of the KerasTuner API\n",
        "\n",
        "Here we use a model builder function to define the classification model.\n",
        "The model builder function returns a compiled model and uses the hyperparameters you define to finetune the model:\n",
        "\n",
        "- n. of units in the first dense layer\n",
        "- learning rate"
      ],
      "metadata": {
        "id": "YsItSK8NCr25"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def model_builder(hp):\n",
        "  model = keras.Sequential()\n",
        "  model.add(keras.layers.Flatten(input_shape=(30,))) ## n. of features in the BreastCancer dataset\n",
        "\n",
        "  # Tune the number of units in the first Dense layer\n",
        "  # Choose an optimal value between 16-128\n",
        "  hp_units = hp.Int('units', min_value=16, max_value=128, step=16)\n",
        "  model.add(keras.layers.Dense(units=hp_units, activation='relu'))\n",
        "  model.add(keras.layers.Dense(10))\n",
        "\n",
        "  # Tune the learning rate for the optimizer\n",
        "  # Choose an optimal value from 0.01, 0.001, or 0.0001\n",
        "  hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
        "\n",
        "  model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
        "                loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "VZ4YSk0RCexA"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hyperparamaters to be explored\n",
        "\n",
        "The Keras Tuner has four tuners available: i) RandomSearch, ii) Hyperband, iii) BayesianOptimization, iv) Sklearn.\n",
        "In this tutorial, you use the `Hyperband tuner`.\n",
        "\n",
        "To instantiate the Hyperband tuner, you must specify the hypermodel, the objective to optimize and the maximum number of epochs to train (`max_epochs`)."
      ],
      "metadata": {
        "id": "NSpo_yEOC7Xp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tuner = kt.Hyperband(model_builder,\n",
        "                     objective='val_accuracy',\n",
        "                     max_epochs=10,\n",
        "                     factor=3, ## factor: Integer, the reduction factor for the number of epochs and number of models for each bracket. Defaults to 3.\n",
        "                     directory='my_dir',\n",
        "                     project_name='intro_to_kt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JDpkmFwuDKUA",
        "outputId": "2b549788-e857-47f9-b661-9f053c7c233c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reloading Tuner from my_dir/intro_to_kt/tuner0.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a callback to stop training early after reaching a certain value for the validation loss.\n",
        "\n"
      ],
      "metadata": {
        "id": "gACF8BFaIRjH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)"
      ],
      "metadata": {
        "id": "1NgARx_yDXvY"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuner.search(x_train, y_train, epochs=50, validation_split=0.2, callbacks=[stop_early], overwrite=True,)\n",
        "\n",
        "# Get the optimal hyperparameters\n",
        "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "\n",
        "print(f\"\"\"\n",
        "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
        "layer is {best_hps.get('units')} and the optimal learning rate for the optimizer\n",
        "is {best_hps.get('learning_rate')}.\n",
        "\"\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0x-tyNQyDeM5",
        "outputId": "42a279f5-22b6-4dfa-ac59-5613d724dd8c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
            "layer is 384 and the optimal learning rate for the optimizer\n",
            "is 0.001.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train the model"
      ],
      "metadata": {
        "id": "SNK7hOf7FhNJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the model with the optimal hyperparameters and train it on the data for 50 epochs\n",
        "model = tuner.hypermodel.build(best_hps)\n",
        "history = model.fit(x_train, y_train, epochs=50, validation_split=0.2)\n",
        "\n",
        "val_acc_per_epoch = history.history['val_accuracy']\n",
        "best_epoch = val_acc_per_epoch.index(max(val_acc_per_epoch)) + 1\n",
        "print('Best epoch: %d' % (best_epoch,))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9zYigxGmFi8J",
        "outputId": "bdff60b9-927c-4cbd-9d61-491df94dc576"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 331ms/step - accuracy: 0.3940 - loss: 1.9809 - val_accuracy: 0.9231 - val_loss: 0.6860\n",
            "Epoch 2/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9353 - loss: 0.5353 - val_accuracy: 0.9121 - val_loss: 0.3132\n",
            "Epoch 3/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9501 - loss: 0.2437 - val_accuracy: 0.9341 - val_loss: 0.2081\n",
            "Epoch 4/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9668 - loss: 0.1592 - val_accuracy: 0.9341 - val_loss: 0.1616\n",
            "Epoch 5/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9798 - loss: 0.1217 - val_accuracy: 0.9451 - val_loss: 0.1360\n",
            "Epoch 6/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9798 - loss: 0.1004 - val_accuracy: 0.9780 - val_loss: 0.1192\n",
            "Epoch 7/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9879 - loss: 0.0868 - val_accuracy: 0.9780 - val_loss: 0.1065\n",
            "Epoch 8/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9879 - loss: 0.0771 - val_accuracy: 0.9890 - val_loss: 0.0962\n",
            "Epoch 9/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9890 - loss: 0.0695 - val_accuracy: 0.9890 - val_loss: 0.0877\n",
            "Epoch 10/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9881 - loss: 0.0634 - val_accuracy: 0.9890 - val_loss: 0.0809\n",
            "Epoch 11/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9881 - loss: 0.0583 - val_accuracy: 0.9890 - val_loss: 0.0753\n",
            "Epoch 12/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9881 - loss: 0.0539 - val_accuracy: 0.9890 - val_loss: 0.0707\n",
            "Epoch 13/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9881 - loss: 0.0501 - val_accuracy: 0.9890 - val_loss: 0.0669\n",
            "Epoch 14/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9881 - loss: 0.0467 - val_accuracy: 0.9890 - val_loss: 0.0638\n",
            "Epoch 15/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9881 - loss: 0.0436 - val_accuracy: 0.9890 - val_loss: 0.0613\n",
            "Epoch 16/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9896 - loss: 0.0409 - val_accuracy: 0.9890 - val_loss: 0.0593\n",
            "Epoch 17/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9896 - loss: 0.0383 - val_accuracy: 0.9890 - val_loss: 0.0577\n",
            "Epoch 18/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9896 - loss: 0.0360 - val_accuracy: 0.9890 - val_loss: 0.0564\n",
            "Epoch 19/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9896 - loss: 0.0338 - val_accuracy: 0.9890 - val_loss: 0.0554\n",
            "Epoch 20/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9896 - loss: 0.0317 - val_accuracy: 0.9890 - val_loss: 0.0547\n",
            "Epoch 21/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9896 - loss: 0.0298 - val_accuracy: 0.9890 - val_loss: 0.0543\n",
            "Epoch 22/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9896 - loss: 0.0280 - val_accuracy: 0.9780 - val_loss: 0.0540\n",
            "Epoch 23/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9937 - loss: 0.0263 - val_accuracy: 0.9780 - val_loss: 0.0538\n",
            "Epoch 24/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9937 - loss: 0.0248 - val_accuracy: 0.9780 - val_loss: 0.0536\n",
            "Epoch 25/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9937 - loss: 0.0233 - val_accuracy: 0.9780 - val_loss: 0.0535\n",
            "Epoch 26/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9978 - loss: 0.0219 - val_accuracy: 0.9780 - val_loss: 0.0535\n",
            "Epoch 27/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9978 - loss: 0.0206 - val_accuracy: 0.9780 - val_loss: 0.0534\n",
            "Epoch 28/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9978 - loss: 0.0195 - val_accuracy: 0.9780 - val_loss: 0.0534\n",
            "Epoch 29/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9978 - loss: 0.0184 - val_accuracy: 0.9780 - val_loss: 0.0534\n",
            "Epoch 30/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9978 - loss: 0.0173 - val_accuracy: 0.9780 - val_loss: 0.0535\n",
            "Epoch 31/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9978 - loss: 0.0164 - val_accuracy: 0.9670 - val_loss: 0.0535\n",
            "Epoch 32/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9978 - loss: 0.0155 - val_accuracy: 0.9670 - val_loss: 0.0534\n",
            "Epoch 33/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0146 - val_accuracy: 0.9670 - val_loss: 0.0534\n",
            "Epoch 34/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0139 - val_accuracy: 0.9670 - val_loss: 0.0534\n",
            "Epoch 35/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0131 - val_accuracy: 0.9670 - val_loss: 0.0534\n",
            "Epoch 36/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0125 - val_accuracy: 0.9670 - val_loss: 0.0534\n",
            "Epoch 37/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0118 - val_accuracy: 0.9670 - val_loss: 0.0534\n",
            "Epoch 38/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0112 - val_accuracy: 0.9670 - val_loss: 0.0534\n",
            "Epoch 39/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0107 - val_accuracy: 0.9670 - val_loss: 0.0533\n",
            "Epoch 40/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0102 - val_accuracy: 0.9670 - val_loss: 0.0533\n",
            "Epoch 41/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0097 - val_accuracy: 0.9670 - val_loss: 0.0532\n",
            "Epoch 42/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0092 - val_accuracy: 0.9670 - val_loss: 0.0532\n",
            "Epoch 43/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0088 - val_accuracy: 0.9670 - val_loss: 0.0531\n",
            "Epoch 44/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0084 - val_accuracy: 0.9670 - val_loss: 0.0531\n",
            "Epoch 45/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0080 - val_accuracy: 0.9670 - val_loss: 0.0532\n",
            "Epoch 46/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0077 - val_accuracy: 0.9670 - val_loss: 0.0531\n",
            "Epoch 47/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0073 - val_accuracy: 0.9670 - val_loss: 0.0530\n",
            "Epoch 48/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0070 - val_accuracy: 0.9670 - val_loss: 0.0530\n",
            "Epoch 49/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0067 - val_accuracy: 0.9670 - val_loss: 0.0529\n",
            "Epoch 50/50\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0064 - val_accuracy: 0.9670 - val_loss: 0.0529\n",
            "Best epoch: 8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hypermodel = tuner.hypermodel.build(best_hps)\n",
        "\n",
        "# Retrain the model\n",
        "hypermodel.fit(x_train, y_train, epochs=best_epoch, validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BDJ7clSfFqmr",
        "outputId": "059337f8-9617-45f5-ddd4-661e0703bc51"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 102ms/step - accuracy: 0.7049 - loss: 1.0283 - val_accuracy: 0.9670 - val_loss: 0.0722\n",
            "Epoch 2/5\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9884 - loss: 0.0625 - val_accuracy: 0.9890 - val_loss: 0.0557\n",
            "Epoch 3/5\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9866 - loss: 0.0540 - val_accuracy: 0.9451 - val_loss: 0.0813\n",
            "Epoch 4/5\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9896 - loss: 0.0440 - val_accuracy: 0.9780 - val_loss: 0.0485\n",
            "Epoch 5/5\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9896 - loss: 0.0284 - val_accuracy: 0.9670 - val_loss: 0.0471\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7891281861e0>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval_result = hypermodel.evaluate(x_val, y_val)\n",
        "print(\"[test loss, test accuracy]:\", eval_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CRj0LdcUFwFi",
        "outputId": "6b119bcd-5ee1-4954-cb34-7df68472153f"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 160ms/step - accuracy: 0.9647 - loss: 0.1129\n",
            "[test loss, test accuracy]: [0.14574988186359406, 0.9561403393745422]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Further steps\n",
        "\n",
        "The code above is a **very** minimal example and works as a starting point. Stuff to consider:\n",
        "\n",
        "* each combination of hyperparameter is trained once, with a 70/30 default split. Using `.evaluate_models()` it's possible to do a proper k-fold crossvalidation (see [scan documentation](https://autonomio.github.io/talos/#/Scan), search \"evaluate_models\")\n",
        "* the default approach of trying all the combinations can become unfeasible very quickly. The `Scan` function supports several policies for sampling a subset of the hyperparameter space. See the [Towardsdatascience's tutorial](https://towardsdatascience.com/tune-the-hyperparameters-of-your-deep-learning-networks-in-python-using-keras-and-talos-2a2a38c5ac31) for a more in-depth example"
      ],
      "metadata": {
        "id": "miy4ArJAAF7d"
      }
    }
  ]
}