{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"code_11 [EXERCISE] chest x rays (data augm, regul).ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyNBGsBzlnKKU6I0XgoI236e"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"a-TykfLxN6_L"},"source":["# Chest X ray problem\n","\n","Binary classification problem, we are asked to classify chest X rays from patients and tell which are sick and which are healty.\n","\n","The dataset is deposited [here](https://www.kaggle.com/paultimothymooney/chest-xray-pneumonia).\n","\n","For a \"heavy guns\" solution for this problem (with data augmentation, learning rate decay, memory optimization and other neat advanced stuff) see [here](https://www.kaggle.com/amyjang/tensorflow-pneumonia-classification-on-x-rays)"]},{"cell_type":"markdown","metadata":{"id":"066Hk1V5_AP2"},"source":["# Config\n","\n","These constants are given for the exercise."]},{"cell_type":"code","metadata":{"id":"NiaFDmq3-2qq"},"source":["#where the data are stored\n","data_url = 'http://www.jackdellequerce.com/data/reduced_chest_xray.zip'\n","\n","#where to place the data\n","download_target_imgs = '/content/data/'\n","base_dir = download_target_imgs + 'reduced_chest_xray/'\n","\n","#Keras constants\n","BATCH_SIZE = 20\n","IMAGE_SIZE = [128, 128]\n","IMAGE_SHAPE = (IMAGE_SIZE[0], IMAGE_SIZE[1] , 3)\n","EPOCHS = 10"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kkcf_AVX_l9D"},"source":["# Data setup\n","\n","The following code ensures that the images are present in `base_dir` folder. If the data is not there it is downloaded and unpacked."]},{"cell_type":"code","metadata":{"id":"OWSI4K5-_nG1"},"source":["import glob     #for checking dir content\n","import os       #for dir creation\n","import requests #for data download\n","import zipfile  #for unpacking zipped files\n","\n","#these two lists should contain the full paths of all train and test images\n","train_filenames = glob.glob(base_dir + 'train/*/*')\n","validation_filenames   = glob.glob(base_dir + 'test/*/*')\n","\n","#let's check that we actually have the data\n","if len(train_filenames) == 0 or len(validation_filenames) == 0:\n","  #either the data was never downloaded or something bad happened\n","  #in any case, we donwload and unzip everything\n","\n","  #room for data\n","  os.makedirs(download_target_imgs, exist_ok=True)\n","\n","  #downloading\n","  r = requests.get(data_url)\n","  open(download_target_imgs + 'local_archive.zip', 'wb').write(r.content)\n","\n","  #unpacking\n","  z = zipfile.ZipFile(download_target_imgs + 'local_archive.zip')\n","  z.extractall(path = download_target_imgs)\n","\n","  #at this point data is there, we are ready to get the list of files\n","  train_filenames = glob.glob(base_dir + 'train/*/*')\n","  validation_filenames   = glob.glob(base_dir + 'test/*/*')\n","\n","#whatever the original case, at this point we have the files\n","print('Available images for train: ' + str(len(train_filenames)))\n","print('Available images for validation: ' + str(len(validation_filenames)))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lVybJWNWBKdZ"},"source":["# Data loading - ImageDataGenerator\n","\n","We are going to use [ImageDataGenerator](https://keras.io/api/preprocessing/image/#imagedatagenerator-class) for loading the images from the local memory.\n","\n","`ImageDataGenerator` class is defined in `keras.preprocessing.image` submodule and can be used for data augmentation and general data handling. \n","\n","When working with images it is important to rescale them in from the 0-255 range to 0-1, as explained in details [here](https://github.com/Arsey/keras-transfer-learning-for-oxford102/issues/1\n",").\n","\n","**ASSIGNMENT**: In the next snipped you need to import `ImageDataGenerator` and then declare two objects named `train_datagen` and `validation_datagen`. Both need a rescaling factor or 1.0/255<br>\n","The \".0\" part is important so python will do a floating point division and not an integer division, in fact:\n","\n","- 1.0/255 → 0,003921569\n","- 1/255 → 0\n","\n","**OPTIONAL ASSIGNMENT**: do some data augmentation telling `train_datagen` to do horizontal flips. Important: never do data augmentation on validation set. Can you guess what the consequences would be?"]},{"cell_type":"code","metadata":{"id":"8A8XsNRC_xZF"},"source":["### YOUR CODE HERE ###\n","#import ImageDataGenerator\n","\n","#declare two objects\n","######################"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jh56-KGTbMpu"},"source":["In so far you have declared the `ImageDataGenerator` objects, but you have not linked them to the actual files. It's now time to do so.\n","\n","**ASSIGNMENT** use the [flow_from_directory()](https://keras.io/api/preprocessing/image/#flowfromdirectory-method) method to link the `validation_datagen` object to its folder.\n","\n","**NOTE**: parameter `batch_size` on train dataset influences the amount of memory required. Usually the bigger the better, but the system can easily become overloaded. On validation dataset it is **important** to give a number that exactly divides the number of available samples, otherwise some samples will never be used. When in doubt put it to 1 (only for validation).  "]},{"cell_type":"code","metadata":{"id":"k28NTVc-UBWK"},"source":["#let's put the dirs in a handy place\n","train_dir = os.path.join(base_dir, 'train')\n","validation_dir = os.path.join(base_dir, 'test')\n","\n","#linking the actual data\n","train_generator = train_datagen.flow_from_directory(\n","        # This is the target directory\n","        train_dir,\n","        # All images will be resized\n","        target_size=IMAGE_SIZE,\n","        batch_size=BATCH_SIZE,\n","        # We have two classes, we'll work in binary mode\n","        class_mode='binary')\n","\n","### YOUR CODE HERE ###\n","######################"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VsJe3QdjFQFg"},"source":["# Architecture - Define\n","\n","It's now time to define an architecture. You'll use the usual [Sequential model](https://keras.io/guides/sequential_model/).\n","\n","**ASSIGNMENT**: Declare a model with the following layers:\n","\n","1. [Conv2D layer](https://keras.io/api/layers/convolution_layers/convolution2d/), 32 nodes, 3x3 kernel, \"same\" padding, \"relu\" activation\n","2. [MaxPooling2D layer](https://keras.io/api/layers/pooling_layers/max_pooling2d/), 2x2 pool size\n","3. another Conv2D layer, this time 64 nodes, everything else same as above\n","4. another MaxPooling2D, same as above\n","5. [Flatten layer](https://keras.io/api/layers/reshaping_layers/flatten/)\n","6. [Dense layer](https://keras.io/api/layers/core_layers/dense/), used as output, \"sigmoid\" activation function. Can you guess the number of nodes?\n","\n","The first layer is the input layer and requires also an `input_shape`, which you find in the `IMAGE_SHAPE` constant you declared above.\n","\n","**OPTIONAL ASSIGNMENT** put a Dropout later after the first MaxPooling2D with a rate of 0.2. Do you need to change something else in the code?\n"]},{"cell_type":"code","metadata":{"id":"824q9YfpCyvz"},"source":["from keras.models import Sequential\n","from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n","\n","#let's declare an empty model\n","model = Sequential()\n","\n","### YOUR CODE HERE ###\n","######################"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eko67WVQFYvR"},"source":["# Architecture - Take a look\n","\n","You have defined the architecture, it's time to take a look at your work. Keras offers two options: \n","\n","* the [.summary()](https://keras.io/api/models/model/#summary-method) method built-in your model object\n","* [plot_model()](https://keras.io/api/utils/model_plotting_utils/#plotmodel-function) function from `keras.utils.vis_utils` package.\n","\n","**ASSIGNMENT** invoke either `.build()` (easy) or `plot_model()` (more complicated), take a look inside your model and verify that everything is as expected in terms of number of layers, output size and so forth."]},{"cell_type":"code","metadata":{"id":"Bd0J3rW9FaN8"},"source":["### YOUR CODE HERE ###\n","\n","######################"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hv6BvycrG16o"},"source":["# Architecture - Compile\n","\n","So far you have defined the topology of your network, it's now time to specify how you are going to measure its performance.\n","\n","**ASSIGNMENT** invoke the [.compile()](https://keras.io/api/models/model_training_apis/#compile-method)  method for your model, specifying the [loss function](https://keras.io/api/losses/) (we are doing binary classification, so 'binary_crossentropy' is the standard choice)\n","\n","**OPTIONAL ASSIGNMENT 1**: ask keras to keep track of an extra metric, 'accuracy'. Keep in mind that `.compile()` expects a list of strings when specifying metrics, even if only one element is present.\n","\n","**OPTIONAL ASSIGNMENT 2**: default optimizer is [RMSprop](https://keras.io/api/optimizers/rmsprop/), with a default learning rate of 0.001. Declare the optimizer so that the used learning rate is 0.00002. "]},{"cell_type":"code","metadata":{"id":"iKB2yjhDG4hy"},"source":["### YOUR CODE HERE ###\n","\n","\n","######################"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KmZxgrc2GNTE"},"source":["# Train\n","\n","It's finally time to train your model using the [.fit()](https://keras.io/api/models/model_training_apis/#fit-method) method.\n","\n","**ASSIGNMENT**: train your model speifying that:\n","\n","* your train data (argument `x`) is in `train_generator`\n","* your validation data (argument `validation_data`) is in `validation_generator`\n","* the desider number of epochs (argument `epochs`) is in the declared constant `EPOCHS`\n","* `verbose` level = 2 so that we can take a look at what's happening\n","\n","The returned object should go in a new variable called `train_log`"]},{"cell_type":"code","metadata":{"id":"pTGAZgNkGFJt"},"source":["### YOUR CODE HERE ###\n","\n","\n","######################"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yltaSPLFLV0X"},"source":["# Support function for plotting metrics\n","\n","The following function is a small utility that allows for plotting loss and all the metrics returned by a `.fit()` call. Just execute the snippet so that the function is declared. Or, if you are curious, take a look at the code :)"]},{"cell_type":"code","metadata":{"id":"d57KmwRHKpN8"},"source":["import matplotlib.pyplot as plt\n","\n","def plot_loss_history(h, title):\n","  for metric in h.history.keys():\n","    #ignoring metrics on validation set, which are implied when\n","    #plotting on training set\n","    if metric.startswith('val_'):\n","      continue\n","    \n","    #if we get here we found a metric on the training set,\n","    #let's plot it\n","    plt.plot(h.history[metric], label = \"Train set\")\n","    plt.plot(h.history[\"val_\" + metric], label = \"Validation set\")\n","    plt.xlabel('Epochs')\n","    plt.title(title + ' - ' + metric)\n","    plt.legend()\n","    plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QHr7PqtFLd0E"},"source":["# Plotting your model performances\n","\n","As a final step, plot loss (and metrics, if present) of your training.\n","\n","**ASSIGNMENT**: use the `plot_loss_history()` you just declared to plot the evolution of your training. What consideration can you do?"]},{"cell_type":"code","metadata":{"id":"LHMOMfuKLRd_"},"source":["### YOUR CODE HERE ###\n","\n","\n","######################"],"execution_count":null,"outputs":[]}]}