{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vU5b1TdjL81b"
      },
      "source": [
        "# Conf"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHO2k6zGL-o7"
      },
      "source": [
        "#where the data are stored\n",
        "data_url = 'http://www.jackdellequerce.com/data/reduced_chest_xray.zip'\n",
        "\n",
        "#where to place the data\n",
        "download_target_imgs = '/content/data/'\n",
        "\n",
        "#Keras constants\n",
        "BATCH_SIZE = 32\n",
        "IMAGE_SIZE = [256, 256]\n",
        "IMAGE_SHAPE = (IMAGE_SIZE[0], IMAGE_SIZE[1] , 3)\n",
        "EPOCHS = 12\n",
        "\n",
        "###############################################\n",
        "# https://github.com/fchollet/deep-learning-with-python-notebooks/blob/master/5.3-using-a-pretrained-convnet.ipynb\n",
        "# https://github.com/Bixi81/Python-ml/blob/master/keras_pretrained_imagerec_multiclass.py\n",
        "\n",
        "# DIR with training images\n",
        "base_dir = '/content/data/reduced_chest_xray/'\n",
        "# Number training images\n",
        "ntrain = 300\n",
        "# Number validation images\n",
        "nval  = 100\n",
        "# Batch size\n",
        "batch_size = 20 #20\n",
        "# Epochs\n",
        "ep = 50\n",
        "# Number of classes (for training, output layer)\n",
        "nclasses = 2\n",
        "###############################################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8AQ1yCg1LeII"
      },
      "source": [
        "# Data setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQ19yZi9L2Yb"
      },
      "source": [
        "import os\n",
        "import time\n",
        "import subprocess\n",
        "from urllib.request import urlopen\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "import glob\n",
        "import requests\n",
        "import zipfile\n",
        "\n",
        "#these two lists should contain the full paths of all train and validation images\n",
        "train_filenames = glob.glob(download_target_imgs + 'reduced_chest_xray/train/*/*')\n",
        "val_filenames   = glob.glob(download_target_imgs + 'reduced_chest_xray/test/*/*')\n",
        "\n",
        "#let's check that we actually have the data\n",
        "if len(train_filenames) == 0 or len(val_filenames) == 0:\n",
        "  #either the data was never downloaded or something bad happened\n",
        "  #in any case, we donwload and unzip everything\n",
        "\n",
        "  #room for data\n",
        "  os.makedirs(download_target_imgs, exist_ok=True)\n",
        "\n",
        "  #downloading\n",
        "  r = requests.get(data_url)\n",
        "  open(download_target_imgs + 'local_archive.zip', 'wb').write(r.content)\n",
        "\n",
        "  #unpacking\n",
        "  z = zipfile.ZipFile(download_target_imgs + 'local_archive.zip')\n",
        "  z.extractall(path = download_target_imgs)\n",
        "\n",
        "  #at this point data is there, we are ready to get the list of files\n",
        "  train_filenames = glob.glob(download_target_imgs + 'reduced_chest_xray/train/*/*')\n",
        "  val_filenames   = glob.glob(download_target_imgs + 'reduced_chest_xray/test/*/*')\n",
        "\n",
        "#whatever the original case, at this point we have the files\n",
        "print('Available images for train: ' + str(len(train_filenames)))\n",
        "print('Available images for validation: ' + str(len(val_filenames)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s3yjy8MMLjEU"
      },
      "source": [
        "# CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n3RzxKIBbq9N"
      },
      "source": [
        "## Import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BnegHgsyblgQ"
      },
      "source": [
        "\n",
        "import os, datetime\n",
        "import numpy as np\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras import models, layers, optimizers, regularizers\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "from keras.layers import Dense, Dropout, Activation\n",
        "from PIL import ImageFile\n",
        "import statistics\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WVp-9jJ2cJT4"
      },
      "source": [
        "## Data setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fnfRDAi_ctLz"
      },
      "source": [
        "## Data generators"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mPIDnGqCcpAy"
      },
      "source": [
        "#why rescale: https://github.com/Arsey/keras-transfer-learning-for-oxford102/issues/1\n",
        "\n",
        "start = datetime.datetime.now()\n",
        "\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "validation_dir = os.path.join(base_dir, 'test')\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "      rescale=1./255,\n",
        "      rotation_range=10,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      horizontal_flip=False,\n",
        "      fill_mode='nearest')\n",
        "\n",
        "\n",
        "# Note that the validation data should not be augmented!\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        # This is the target directory\n",
        "        train_dir,\n",
        "        # All images will be resized to 150x150\n",
        "        target_size=(150, 150),\n",
        "        batch_size=batch_size,\n",
        "        # Since we use categorical_crossentropy loss, we need binary labels\n",
        "        class_mode='categorical')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "        validation_dir,\n",
        "        target_size=(150, 150),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "llxaVRnFcXL7"
      },
      "source": [
        "## Model - architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mm5JzQ3Rca1T"
      },
      "source": [
        "conv_base = VGG16(weights='imagenet', include_top=False, input_shape=(150, 150, 3))\n",
        "conv_base.trainable = True\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(conv_base)\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(nclasses, activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DR3EEQkUcdun"
      },
      "source": [
        "## Model - compile"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wW5dhe4vc8Ln"
      },
      "source": [
        "# Model compile / fit\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizers.RMSprop(learning_rate=2e-5),\n",
        "              metrics=['acc'])\n",
        "\n",
        "#here we configure two callbacks, early stopping moniroting the loss, and\n",
        "#a learning rate reduction for fine tuning\n",
        "#more on callbacks: https://keras.io/api/callbacks/\n",
        "\n",
        "es = EarlyStopping(monitor='loss', mode='min', min_delta=0.001, verbose=1, patience=40, restore_best_weights=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='loss', mode='min', factor=0.9, patience=15, min_lr=1e-20, verbose=1, cooldown=3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JLza80Khc_ey"
      },
      "source": [
        "## Model - fit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zrk7tjNwdCfQ"
      },
      "source": [
        "history = model.fit(\n",
        "      train_generator,\n",
        "      steps_per_epoch=round(ntrain/batch_size,0),\n",
        "      epochs=ep,\n",
        "      validation_data=validation_generator,\n",
        "      validation_steps=round(nval/batch_size,0),\n",
        "      verbose=2,\n",
        "      callbacks=[es, reduce_lr])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BPzmYOmANGRY"
      },
      "source": [
        "## Closing remarks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tUxHoegINMcG"
      },
      "source": [
        "# Save model\n",
        "model.save(os.path.join(download_target_imgs, 'keras_multiclass_model.hdf5'))\n",
        "end = datetime.datetime.now()\n",
        "delta = str(end-start)\n",
        "\n",
        "# Metrics\n",
        "acc = history.history['acc']\n",
        "acc = acc[-5:]\n",
        "val_acc = history.history['val_acc']\n",
        "val_acc = val_acc[-5:]\n",
        "loss = history.history['loss']\n",
        "loss = loss[-5:]\n",
        "val_loss = history.history['val_loss']\n",
        "val_loss = val_loss[-5:]\n",
        "\n",
        "# End statement\n",
        "print(\"============================================\")\n",
        "print(\"Time taken (h/m/s): %s\" %delta[:7])\n",
        "print(\"============================================\")\n",
        "print(\"Metrics (average last five steps)\")\n",
        "print(\"--------------------------------------------\")\n",
        "print(\"Loss       %.3f\" %statistics.mean(loss))\n",
        "print(\"Val. Loss  %.3f\" %statistics.mean(val_loss))\n",
        "print(\"--------------------------------------------\")\n",
        "print(\"Acc.       %.3f\" %statistics.mean(acc))\n",
        "print(\"Val. Acc.  %.3f\" %statistics.mean(val_acc))\n",
        "print(\"============================================\")\n",
        "print(\"Epochs:    %s\" %(ep))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}