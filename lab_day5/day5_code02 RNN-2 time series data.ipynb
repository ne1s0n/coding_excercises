{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"KoovfFRefZDS"},"source":["## A RNN model to analyse climate data\n","\n","RNN are a type of deep learning architecture suited to work with **longitudinal data**, e.g. time series data.\n","\n","Time series data include many types of data, like:\n","\n","- economic indicators (e.g. *quarterly GDP*, *monthly inflation*)\n","- patient health evolution metrics (e.g.*ECG data*)\n","\n","Time series data include a fundamental **time component**, and are often used in **forecasting problems**.\n","\n","Here we use maximum daily temepratures in Melbourne (Australia), over the period 1981 - 1990, as an example to train a recurrent neural network (RNN) model.\n"]},{"cell_type":"code","metadata":{"id":"AlbgjOideXGd"},"source":["## import relevant libraries\n","import numpy as np\n","import datetime as dt\n","import pandas as pd\n","import pandas_datareader\n","from pandas_datareader import data"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jWXryuNQgzak"},"source":["## getting the data\n","DATAURL = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/daily-max-temperatures.csv'\n","df = pd.read_csv(DATAURL)\n","print(\"N. of row in dataframe: \",len(df))\n","df.head()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JjJesTIXg6wL"},"source":["We will use Melbourne maximum daily temperature (`Temperature`) in a forecasting problem\n","\n","First, we split data into train/test: we use the last year as test, and all remaining observations as training set."]},{"cell_type":"code","metadata":{"id":"xaLuz6IPhGmw"},"source":["temperature = df['Temperature']\n","n = len(temperature) - 365 # training set\n","print('The size of the training data is', n)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Let's have a look at the distribution of the training and testing data:"],"metadata":{"id":"TxzKF2rxsC6F"}},{"cell_type":"code","source":["df['Temperature'][:n].plot()"],"metadata":{"id":"yWTE0Cr7sB-4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df['Temperature'][n:].plot()"],"metadata":{"id":"IE-HgMqnr8V6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train = list(temperature)[:n] #first n temperatures\n","test = list(temperature)[n:] #remaining temperatures"],"metadata":{"id":"sUZ-bMKosOi6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NVEiXjRchb4O"},"source":["#### Data representation\n","\n","We have two series of data (temperatures), for training and for testing.\n","For training, we have therefore one data series, and we need to use an appropriate representation for the feature data to be used for prediction (forecasting).\n","\n","A common possibility is to use preceding values in the series to predict the next one(s): for instance, a sliding-window appraoch can be used (see figure below)\n","\n","<img src=\"https://miro.medium.com/max/700/1*murkc0tNsvgdQDVgKqSdfQ.png\">"]},{"cell_type":"code","metadata":{"id":"2GEUUVPBheR7"},"source":["## prepare the training data\n","windowSize, X_train, y_train = 10, [], [] #initialize lists and set window size\n","for index in range(len(train)-windowSize): #we must end at train-windowSize to avoid the windowSize going past the end\n","    X_train.append(train[index:index+windowSize]) #append the range from index to index+windowSize to x\n","    y_train.append(train[index+windowSize]) #append the next value to the y\n","\n","X_train,y_train = np.array(X_train), np.array(y_train) #convert to numpy array\n","X_train = X_train.reshape((len(X_train), windowSize, 1)) #reshape X_train to proper 3-d array\n","\n","print(y_train.shape)\n","print(X_train.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5HD0lB7bFdyZ"},"source":["X_train[0,0:9,0]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"svB7tQGOOACF"},"source":["y_train[0]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zUileKvTiZOd"},"source":["## prepare the test data\n","windowSize, X_test, y_test = 10, [], [] #initialize lists and set window size\n","for index in range(len(test)-windowSize): #we must end at train-windowSize to avoid the windowSize going past the end\n","    X_test.append(test[index:index+windowSize]) #append the range from index to index+windowSize to x\n","    y_test.append(test[index+windowSize]) #append the next value to the y\n","\n","X_test,y_test = np.array(X_test), np.array(y_test) #convert to numpy array\n","X_test = X_test.reshape((len(X_test), windowSize, 1)) #reshape X_train to proper 3-d array\n","\n","print(y_test.shape)\n","print(X_test.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GGsAu0p5itmg"},"source":["### Simple RNN\n","\n","Let's start with a simple RNN model:\n","- one RNN layer (12 units)\n","- one dense layer (output layer: one number per timepoint, regression problem)"]},{"cell_type":"code","metadata":{"id":"HwYwQ8tniwrY"},"source":["from keras import Sequential\n","from keras.layers import SimpleRNN, Dense, Input\n","\n","import math\n","import tensorflow as tf\n","import matplotlib.pyplot as plt"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":[" input_shape = (windowSize,1)\n"," print(input_shape)"],"metadata":{"id":"K7kbw1vqXU5k"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QZWI5whNi_NI"},"source":["model = Sequential() #initializing sequential model, layers can be added sequentially with model.add\n","model.add(Input(input_shape))\n","model.add(SimpleRNN(12)) #simple recurrent layer, 10 neurons & process 10x1 sequences\n","model.add(Dense(1,activation='linear')) #linear output because this is a regression problem\n","model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WhktrAc6jHqp"},"source":["- 12 units\n","- recurrent weights (states/activations are fed recursively): matrix $\\mathbf{W_{aa}}(u,u)$\n","- input weights: n. units x n. features (here the number of features is 1: one sequence of previous values). For the blood pressure example, this would be 2 (diastolic and sistolic pressure values)\n","- one bias term per unit\n","\n","$$\n","168 = 12 \\text{ units} \\cdot 12 \\text{ units} + 12 \\text{ units} \\cdot 1 \\text{ feature} + 12 \\text{ bias terms}\n","$$"]},{"cell_type":"code","metadata":{"id":"FHcYUkZajINl"},"source":["## let's fit the model\n","loss_function = 'mse'\n","optimizer_algorithm = 'Adam'\n","metrics_list = ['mae',tf.keras.metrics.RootMeanSquaredError()]\n","n_epochs = 20\n","\n","model.compile(loss=loss_function, optimizer=optimizer_algorithm, metrics=metrics_list)\n","history = model.fit(X_train,y_train,epochs=n_epochs, verbose=1, validation_data=(X_test, y_test))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"U9L2LqpLja4l"},"source":["print(history.history.keys())\n","plt.plot(history.history['mae'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HA2t5Cw6jmg8"},"source":["## let's look at predictions\n","predictions = model.predict(X_test)\n","nrow = len(y_test)\n","temp = y_test.reshape(nrow,1)\n","\n","## MAPE\n","ptc_err = 100*(abs(predictions - temp)/abs(temp))\n","mape = ptc_err.mean() # mean absolute percentage error\n","\n","## RMSE\n","sqerr = (predictions - y_test)**2\n","rmse = math.sqrt(sqerr.mean())\n","\n","## CORRELATION\n","\n","\n","print(\"accuracy (measured as MAPE) is: \", round(mape,2), \" %\")\n","print(\"accuracy (measured as RMSE) is: \", round(rmse,2), \" degrees\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_pred = pd.Series(predictions[:,0])\n","y = pd.Series(y_test.astype(float))\n","\n","## CORRELATION\n","print(y_pred.corr(y))"],"metadata":{"id":"A19SpvzGWr9j"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"P0rtjBf6jMfB"},"source":["res = pd.DataFrame(dict(y_test = y, y_pred = y_pred)).reset_index()\n","print(res)\n","res[['y_test','y_pred']].plot()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ltm85YMAkUvY"},"source":["Why is it so? We see that predictions fail to capture the highest temperatures at both extremes (left and right, australian summer).\n","\n","**QUESTION: what is going on?**"]},{"cell_type":"markdown","metadata":{"id":"Vfsnz7k4kzU-"},"source":["### Data preprocessing\n","\n","We may want to consider to normalise the data, that now are on the celsius degree scale.\n","\n","First, we calculate the average and the standard deviation on the training data:"]},{"cell_type":"code","metadata":{"id":"fEKUaacVk8tZ"},"source":["avg = df['Temperature'][:n].mean()\n","dev_std = df['Temperature'][:n].std()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Now, we can normalize (standardize) the data (both training and test):"],"metadata":{"id":"EJtAhCqLunnm"}},{"cell_type":"code","source":["train = (train-avg)/dev_std\n","test = (test-avg)/dev_std"],"metadata":{"id":"Nl-R_lfduZuS"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"J26kjaHLlHxu"},"source":["train"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.plot(train)"],"metadata":{"id":"12I2AoTzXxTv"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HZYltq3illjz"},"source":["plt.plot(test)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2DYx1IwelrU6"},"source":["Now we need to recreate the sliding-window representation (again, both for the training and the test data):"]},{"cell_type":"code","metadata":{"id":"5rtlCpjxltEI"},"source":["## prepare the training data\n","windowSize, X_train, y_train = 10, [], [] #initialize lists and set window size\n","for index in range(len(train)-windowSize): #we must end at train-windowSize to avoid the windowSize going past the end\n","    X_train.append(train[index:index+windowSize]) #append the range from index to index+windowSize to x\n","    y_train.append(train[index+windowSize]) #append the next value to the y\n","\n","X_train,y_train = np.array(X_train), np.array(y_train) #convert to numpy array\n","X_train = X_train.reshape((len(X_train), windowSize, 1)) #reshape X_train to proper 3-d array\n","\n","print(y_train.shape)\n","print(X_train.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## prepare the test data\n","windowSize, X_test, y_test = 10, [], [] #initialize lists and set window size\n","for index in range(len(test)-windowSize): #we must end at train-windowSize to avoid the windowSize going past the end\n","    X_test.append(test[index:index+windowSize]) #append the range from index to index+windowSize to x\n","    y_test.append(test[index+windowSize]) #append the next value to the y\n","\n","X_test,y_test = np.array(X_test), np.array(y_test) #convert to numpy array\n","X_test = X_test.reshape((len(X_test), windowSize, 1)) #reshape X_train to proper 3-d array\n","\n","print(y_test.shape)\n","print(X_test.shape)"],"metadata":{"id":"NRorLOBDvBkC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"847MUWK2l4iq"},"source":["Let's fit again the RNN model:"]},{"cell_type":"code","metadata":{"id":"9RzQs9mpl647"},"source":["model = Sequential()\n","model.add(Input(input_shape)) #initializing sequential model, layers can be added sequentially with model.add\n","model.add(SimpleRNN(12)) #simple recurrent layer, 10 neurons & process 10x1 sequences\n","model.add(Dense(1,activation='linear')) #linear output because this is a regression problem\n","model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3-8UZ_yhmAFF"},"source":["## let's fit the model\n","loss_function = 'mse'\n","optimizer_algorithm = 'Adam'\n","metrics_list = ['mae',tf.keras.metrics.RootMeanSquaredError()]\n","n_epochs = 20\n","\n","model.compile(loss=loss_function, optimizer=optimizer_algorithm, metrics=metrics_list)\n","history = model.fit(X_train,y_train,epochs=n_epochs, verbose=1, validation_data=(X_test, y_test))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TZ6QWY-YnK9c"},"source":["plt.plot(history.history['mae'])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["And now, the predictions: first, on the standardized scale"],"metadata":{"id":"xi7wOQyfvi_j"}},{"cell_type":"code","metadata":{"id":"lBeaYxinnbM0"},"source":["## let's look at predictions\n","predictions = model.predict(X_test)\n","nrow = len(y_test)\n","temp = y_test.reshape(nrow,1)\n","\n","## MAPE\n","ptc_err = 100*(abs(predictions - temp)/abs(temp))\n","mape = ptc_err.mean() # mean absolute percentage error\n","\n","## RMSE\n","sqerr = (predictions - y_test)**2\n","rmse = math.sqrt(sqerr.mean())\n","\n","print(\"accuracy (measured as MAPE) is: \", round(mape,2), \" %\")\n","print(\"accuracy (measured as RMSE) is: \", round(rmse,2), \" dev std\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["We see that the shape of the test data is now better captured:"],"metadata":{"id":"FKpFZbl_vr_a"}},{"cell_type":"code","metadata":{"id":"i0ofSVX2oNY8"},"source":["y_pred = pd.Series(predictions[:,0])\n","y = pd.Series(y_test.astype(float))\n","\n","## CORRELATION\n","print(y_pred.corr(y))"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df = pd.DataFrame(dict(y_test = y, y_pred = y_pred)).reset_index()\n","print(df)\n","df[['y_test','y_pred']].plot()"],"metadata":{"id":"cGsY1vRBWhnD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IKC6u6C4oUkF"},"source":["#### Backtransform the data\n","\n","Let's put our data back on the Celsius degrees scale:\n","\n","$$\n","x_{degrees} = \\sigma \\cdot x_{std} + Î¼\n","$$"]},{"cell_type":"code","metadata":{"id":"hZiQW-VHoa1D"},"source":["y_pred = pd.Series(predictions[:,0])\n","y_pred = (y_pred * dev_std) + avg\n","y = pd.Series(y_test.astype(float))\n","y = (y * dev_std) + avg\n","\n","df = pd.DataFrame(dict(y_test = y, y_pred = y_pred)).reset_index()\n","print(df)\n","df[['y_test','y_pred']].plot()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qVhrfA3somKv"},"source":["## MAPE\n","ptc_err = 100*(abs(y_pred - y)/abs(y))\n","mape = ptc_err.mean() # mean absolute percentage error\n","\n","## RMSE\n","sqerr = (y_pred - y)**2\n","rmse = math.sqrt(sqerr.mean())\n","\n","print(\"accuracy (measured as MAPE) is: \", round(mape,2), \" %\")\n","print(\"accuracy (measured as RMSE) is: \", round(rmse,2), \" degrees\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hqF_CJJKZGu8"},"source":["---\n","# END OF LIGHT DEMO PART - from now on: hic sunt leones!\n","---"]},{"cell_type":"markdown","metadata":{"id":"Q3SMxXncrG6B"},"source":["### More RNN layers\n","\n","Let's now make our neural network model more complex by adding layers (going \"deep\").\n","\n","First, a sanity check on the input data:"]},{"cell_type":"code","metadata":{"id":"a3BhgxvkrQzB"},"source":["print(y_train[0:9])\n","print(X_train[0:4,0:4])\n","print(X_test[1:5,1:5])\n","print(y_test[1:10])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"refu8RUYrzBD"},"source":["Now we build, compile and fit the model"]},{"cell_type":"code","metadata":{"id":"h4LeobwfrXId"},"source":["model = Sequential() #initialize model\n","model.add(Input(input_shape))\n","model.add(SimpleRNN(32, return_sequences=True)) #recurrent layer 1, 64 neurons\n","model.add(SimpleRNN(16, return_sequences=True)) #recurrent layer 2, 32 neurons\n","model.add(SimpleRNN(8)) #recurrent layer 3, 16 neurons\n","model.add(Dense(1,activation='linear')) #output dense layer (1 neuron) w/ linear activation\n","model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WufXO14vrdwl"},"source":["loss_function = 'mse'\n","optimizer_algorithm = 'Adam'\n","metrics_list = ['mae',tf.keras.metrics.RootMeanSquaredError()]\n","n_epochs = 20\n","\n","model.compile(loss=loss_function, optimizer=optimizer_algorithm, metrics=metrics_list)\n","history = model.fit(X_train,y_train,epochs=n_epochs, verbose=0, validation_data=(X_test, y_test))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UKBWCpvnrjyJ"},"source":["plt.plot(history.history['mae'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"l8lQt0ossBfc"},"source":["predictions = model.predict(X_test)\n","\n","y_pred = pd.Series(predictions[:,0])\n","y_pred = (y_pred * dev_std) + avg\n","y = pd.Series(y_test.astype(float))\n","y = (y * dev_std) + avg\n","\n","df = pd.DataFrame(dict(y_test = y, y_pred = y_pred)).reset_index()\n","print(df)\n","df[['y_test','y_pred']].plot()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WsMy6K2ttFRp"},"source":["## MAPE\n","ptc_err = 100*(abs(y_pred - y)/abs(y))\n","mape = ptc_err.mean() # mean absolute percentage error\n","\n","## RMSE\n","sqerr = (y_pred - y)**2\n","rmse = math.sqrt(sqerr.mean())\n","\n","print(\"accuracy (measured as MAPE) is: \", round(mape,2), \" %\")\n","print(\"accuracy (measured as RMSE) is: \", round(rmse,2), \" degrees\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cPPuZXbytVWf"},"source":["## LSTM models\n","\n","Let's now change the architecture of our RNN model, by using a specialized type of unit: the **long-short term memory** (LSTM) unit (see [here](https://keras.io/api/layers/recurrent_layers/lstm/))"]},{"cell_type":"code","metadata":{"id":"6ncfEDultkUd"},"source":["print(y_train[1:10])\n","print(X_train[1:5,1:5])\n","print(X_test[1:5,1:5])\n","print(y_test[1:10])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CV7s6y2WtpD5"},"source":["from keras.layers import LSTM\n","\n","model = Sequential() #initialize sequential model\n","model.add(Input(input_shape))\n","model.add(LSTM(16, return_sequences=True)) #LSTM layer with 10 neurons\n","# model.add(LSTM(16, return_sequences=True)) #LSTM layer with 10 neurons\n","model.add(LSTM(8)) #LSTM layer with 10 neurons\n","model.add(Dense(1,activation='linear')) #Dense output layer with 1 neuron, linear activation\n","model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yb60pzt4tsn2"},"source":["loss_function = 'mse'\n","optimizer_algorithm = 'Adam'\n","metrics_list = ['mae',tf.keras.metrics.RootMeanSquaredError()]\n","n_epochs = 20\n","\n","model.compile(loss=loss_function, optimizer=optimizer_algorithm, metrics=metrics_list)\n","history = model.fit(X_train,y_train,epochs=n_epochs, verbose=0, validation_data=(X_test, y_test))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"a3V-Yoj1tv5m"},"source":["plt.plot(history.history['mae'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4LvdCKZnt3WX"},"source":["predictions = model.predict(X_test)\n","\n","y_pred = pd.Series(predictions[:,0])\n","y_pred = (y_pred * dev_std) + avg\n","y = pd.Series(y_test.astype(float))\n","y = (y * dev_std) + avg\n","\n","df = pd.DataFrame(dict(y_test = y, y_pred = y_pred)).reset_index()\n","print(df)\n","df[['y_test','y_pred']].plot()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KKSV53ZFuBcX"},"source":["## MAPE\n","ptc_err = 100*(abs(y_pred - y)/abs(y))\n","mape = ptc_err.mean() # mean absolute percentage error\n","\n","## RMSE\n","sqerr = (y_pred - y)**2\n","rmse = math.sqrt(sqerr.mean())\n","\n","print(\"accuracy (measured as MAPE) is: \", round(mape,2), \" %\")\n","print(\"accuracy (measured as RMSE) is: \", round(rmse,2), \" degrees\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qHM1xv6Rugyr"},"source":["### More epochs?"]},{"cell_type":"code","metadata":{"id":"VsvoxVCyuios"},"source":["history = model.fit(X_train,y_train,epochs=200, verbose=0, validation_data=(X_test, y_test))"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.plot(history.history['mae'])"],"metadata":{"id":"-8DjEaQ7QlWU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["predictions = model.predict(X_test)\n","\n","y_pred = pd.Series(predictions[:,0])\n","y_pred = (y_pred * dev_std) + avg\n","y = pd.Series(y_test.astype(float))\n","y = (y * dev_std) + avg\n","\n","df = pd.DataFrame(dict(y_test = y, y_pred = y_pred)).reset_index()\n","print(df)\n","df[['y_test','y_pred']].plot()"],"metadata":{"id":"mUn7SVRPQrcQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## MAPE\n","ptc_err = 100*(abs(y_pred - y)/abs(y))\n","mape = ptc_err.mean() # mean absolute percentage error\n","\n","## RMSE\n","sqerr = (y_pred - y)**2\n","rmse = math.sqrt(sqerr.mean())\n","\n","print(\"accuracy (measured as MAPE) is: \", round(mape,2), \" %\")\n","print(\"accuracy (measured as RMSE) is: \", round(rmse,2), \" degrees\")"],"metadata":{"id":"HGhNRAsMQw24"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VnZya_StUpHl"},"source":["### Simple RNN, more epochs"]},{"cell_type":"code","metadata":{"id":"x6hopWNjUjKL"},"source":["model = Sequential() #initializing sequential model, layers can be added sequentially with model.add\n","model.add(Input(input_shape))\n","model.add(SimpleRNN(10)) #simple recurrent layer, 10 neurons & process 50x1 sequences\n","model.add(Dense(1,activation='linear')) #linear output because this is a regression problem\n","model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4zFdfkteUnA_"},"source":["loss_function = 'mse'\n","optimizer_algorithm = 'Adam'\n","metrics_list = ['mae',tf.keras.metrics.RootMeanSquaredError()]\n","n_epochs = 200\n","\n","model.compile(loss=loss_function, optimizer=optimizer_algorithm, metrics=metrics_list)\n","history = model.fit(X_train,y_train,epochs=n_epochs, verbose=0, validation_data=(X_test, y_test))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vU7WOm_MUy-i"},"source":["predictions = model.predict(X_test)\n","\n","y_pred = pd.Series(predictions[:,0])\n","y_pred = (y_pred * dev_std) + avg\n","y = pd.Series(y_test.astype(float))\n","y = (y * dev_std) + avg\n","\n","df = pd.DataFrame(dict(y_test = y, y_pred = y_pred)).reset_index()\n","print(df)\n","df[['y_test','y_pred']].plot()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IeLsq9mFVbRY"},"source":["## MAPE\n","ytt = df[['y_test']].values\n","ypp = df[['y_pred']].values\n","ptc_err = 100*(abs(ytt - ypp)/abs(ytt))\n","mape = ptc_err.mean() # mean absolute percentage error\n","\n","## RMSE\n","sqerr = (ypp - ytt)**2\n","rmse = math.sqrt(sqerr.mean())\n","\n","print(\"accuracy (measured as MAPE) is: \", round(mape,2), \" %\")\n","print(\"accuracy (measured as RMSE) is: \", round(rmse,2), \" dollars\")"],"execution_count":null,"outputs":[]}]}