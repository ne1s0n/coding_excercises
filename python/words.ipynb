{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem\n",
    "\n",
    "Download the zipped text of a book from a given URL. Count the occurrences of each different word. Print the top 10 most common words, plus mean and median for word occurrence count.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "For this exercise we are going to use Mary Shelley's classic \"Frankenstein; or, The Modern Prometheus\". To avoid relying on external websites I've downloaded and zipped the plain text, which is now hosted in this very git repo under `/data`. The full address for the book is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_url = 'https://github.com/ne1s0n/coding_excercises/raw/master/data/Frankenstein%2C%20or%20the%20Modern%20Prometheus%20(First%20Edition%2C%201818).zip'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data retrieval\n",
    "\n",
    "There are several modules that allow to download files, e.g. \n",
    "[urllib.request module](https://docs.python.org/3/library/urllib.request.html), \n",
    "[urllib2 module](https://docs.python.org/2/library/urllib2.html) (but only in Python 2), \n",
    "and [wget module](https://pypi.org/project/wget/).\n",
    "\n",
    "I suggest using the [requests module](https://requests.readthedocs.io/en/master/), and even the very [python documentation does so](https://docs.python.org/3/library/urllib.request.html#module-urllib.request), but your mileage may vary.\n",
    "\n",
    "The `requests module` approach is to use the `get` method to create a [response object](https://requests.readthedocs.io/en/master/api/#requests.Response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "r = requests.get(book_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a `response object` named r. Let's take a look into it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "application/zip\n",
      "https://raw.githubusercontent.com/ne1s0n/coding_excercises/master/data/Frankenstein%2C%20or%20the%20Modern%20Prometheus%20(First%20Edition%2C%201818).zip\n"
     ]
    }
   ],
   "source": [
    "# Retrieve some meta-data\n",
    "print(r.status_code)\n",
    "print(r.headers['content-type'])\n",
    "print(r.url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If all went well we should see a 200 status code (= OK). If you see something different (especially codes starting with a 4, such as 404) something bad may have happened and you may want to check the list of [HTTP status codes](https://en.wikipedia.org/wiki/List_of_HTTP_status_codes)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing the data without local storage\n",
    "\n",
    "The `requests module` allows to access zipped data transparently via the [.iter_lines() method](https://2.python-requests.org/en/master/api/#requests.Response.iter_lines) of a `response object`. This is very handy, very fast, and we are not going to use it :)\n",
    "\n",
    "For the sake of completeness, it would be something like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we are not executing this code\n",
    "if False:\n",
    "    for line in r.iter_lines():\n",
    "        #do something with one line of the book, such as...\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storing and accessing data locally\n",
    "\n",
    "We want to be able to 1) store zipped data on local memory and to 2) access it at a later time. \n",
    "\n",
    "So, for the first part, we simply store the payload after opening a file pointer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving to local file, you may want to change the path\n",
    "with open('book.txt.zip', 'wb') as f:\n",
    "    #the actual data payload is accessed via .content field\n",
    "    f.write(r.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The book is now stored locally. Since it's a zipped file to access it we need to use the [zipfile module](https://docs.python.org/3/library/zipfile.html).\n",
    "\n",
    "A zip archive can contain more than one file, so the first thing we need to do is to discover the actual list of files in the archive:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Frankenstein, or the Modern Prometheus (First Edition, 1818).txt']\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "z = zipfile.ZipFile('book.txt.zip')\n",
    "nl = z.namelist()\n",
    "print(nl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please note the square brackets: the `.namelist()` method returns a list of file names, and in this case there's a single file in the archive. Let's open it and print the first line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Frankenstein; or, the Modern Prometheus\\n'\n"
     ]
    }
   ],
   "source": [
    "#let's just read one line of the file\n",
    "with z.open(nl[0]) as f:\n",
    "    print(f.readline())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's the first line of the text. Please note the 'b' at the beginning, which tells that the data are not in the form of string but of binary data, here rendered as characters and escaped symbols. Also, there's a newline character at the end of the line (this is normal behaviour for `readline()`). \n",
    "\n",
    "To convert the data to actual strings we need to [decode it to UTF](https://docs.python.org/3/howto/unicode.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frankenstein; or, the Modern Prometheus\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#same as above, let's just read one line\n",
    "with z.open(nl[0]) as f:\n",
    "    print(f.readline().decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It may be hard to tell but there are two \"newlines\" printed: one is the '\\n' from the file (now correctly rendered) and the other is the regular newline after `print()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standard words\n",
    "\n",
    "We are now able to read data from the desired file, and need to start thinking about the task ahead: collect statistics on the word frequency. To do that we need to have a way to standardize words, and in particular:\n",
    "\n",
    "- be case insensitive, so that \"Dog\" and \"dog\" are considered the same word\n",
    "- remove punctuation, so that \"dog,\" is equal to \"dog\"\n",
    "- reject things that are not proper words: numbers and isolated symbols (e.g. hyphens)\n",
    "\n",
    "To ease this process we write a function. For string manipulation we'll use regular expressions through the [re module](https://docs.python.org/3/library/re.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def standardize_word(raw_word):\n",
    "    #case insensitive\n",
    "    word = raw_word.lower()\n",
    "    \n",
    "    #removing what is not letters. This is a gross semplification\n",
    "    #of the many intricacies of language (e.g. we are counting \"Smith's\" as \"smiths\")\n",
    "    #but it will do for this exercise. First step is to compile the\n",
    "    #regular expression\n",
    "    myregex = re.compile((\"[^a-zA-Z]\"))\n",
    "    \n",
    "    #and then apply it to the string so that what is caught by the regular \n",
    "    #expression is substituted with an empty string\n",
    "    word = myregex.sub('', word)\n",
    "    \n",
    "    #if word has become an empty string in means it's a non-word. We could\n",
    "    #return it as is, but it's better to be explicit\n",
    "    if len(word) == 0:\n",
    "        return(None)\n",
    "    else:\n",
    "        return(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function is ready, let's test it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog\n",
      "dog\n",
      "dog\n",
      "None\n",
      "hello\n",
      "whatsthebestcolorblue\n"
     ]
    }
   ],
   "source": [
    "print(standardize_word(\"dog\"))\n",
    "print(standardize_word(\"Dog\"))\n",
    "print(standardize_word(\"dog11\"))\n",
    "print(standardize_word(\"12+3\"))\n",
    "print(standardize_word(\"hello{---}\"))\n",
    "print(standardize_word(\"What's the best color? Blue!\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function works exactly as expected: the passed argument is considered a single word, non-letter characters are removed, all is lower case. It will be our duty to feed only actual words to it and not pieces of sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Counting word frequencies\n",
    "\n",
    "We are now ready to actually count how many instances of each word appears in the text. We'll keep track using a dictionary: keys are words, values are number of appearences. In this way we have a compact representation of our data that guarantees absence of duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tally = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is now a matter of..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#opening the zip archive\n",
    "with zipfile.ZipFile('book.txt.zip') as z:\n",
    "    #opening the first (and only) file in the zip archive\n",
    "    with z.open(nl[0]) as f:\n",
    "        #reading the file line by line\n",
    "        for line in f:\n",
    "            #splitting the words using spaces as separator\n",
    "            #remembering that \"line\" is a binary and we need to decode\n",
    "            #it to string before invoking the string methods\n",
    "            words = line.decode(\"utf-8\").split()\n",
    "            \n",
    "            #each word need to be processed\n",
    "            for w in words:\n",
    "                #standardize it with our handy function\n",
    "                w_st = standardize_word(w)\n",
    "                \n",
    "                #new or old word?\n",
    "                if w_st in tally:\n",
    "                    #old word, update count\n",
    "                    tally[w_st] = tally[w_st] + 1\n",
    "                else:\n",
    "                    #new word, let's add it\n",
    "                    tally[w_st] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we are done! How many different words did we collect?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7016\n"
     ]
    }
   ],
   "source": [
    "print(len(tally))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seven thousands, not bad.  \n",
    "Unfortunately to do statistics on the numbers a dictionary is not very handy. It would better to put data in a `DataFrame` from [pandas module](https://pandas.pydata.org/). Luckily there is a method that actually accepts [dicts as data source](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.from_dict.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>frankenstein</th>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>or</th>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>4053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>modern</th>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prometheus</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peteforsyth</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>httpwikisourceorg</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>httpwwwcreativecommonsorglicensesbysa</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>httpwwwgnuorgcopyleftfdlhtml</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>httpwikisourceorgwikiwikisourcescriptorium</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7016 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            count\n",
       "frankenstein                                   35\n",
       "or                                            192\n",
       "the                                          4053\n",
       "modern                                         18\n",
       "prometheus                                      9\n",
       "...                                           ...\n",
       "peteforsyth                                     1\n",
       "httpwikisourceorg                               1\n",
       "httpwwwcreativecommonsorglicensesbysa           1\n",
       "httpwwwgnuorgcopyleftfdlhtml                    1\n",
       "httpwikisourceorgwikiwikisourcescriptorium      1\n",
       "\n",
       "[7016 rows x 1 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas\n",
    "\n",
    "#creating a data frame\n",
    "#keys become \"index\" (in R that would be row names)\n",
    "#the only available value becomes column 0, which we name \"count\"\n",
    "df = pandas.DataFrame.from_dict(tally, orient='index', columns=['count'])\n",
    "\n",
    "#printing the data frame, which has a built-in print method that\n",
    "#shows the first and last lines, plus a footer with its dimensions\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is exactly as expected: the first words are from title, and the last ones are the final bunch of websites that originally distributed the text. As a trivia, we now know that the word \"Frankenstein\" appears 34 times in the novel, not counting the title.\n",
    "\n",
    "The problem ask us to find the top 10 most common words. So we must sort the data frame by descending order and then print the first part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>4053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>and</th>\n",
       "      <td>2875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i</th>\n",
       "      <td>2728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>of</th>\n",
       "      <td>2537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <td>1965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>my</th>\n",
       "      <td>1666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>1311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in</th>\n",
       "      <td>1067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>that</th>\n",
       "      <td>1013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>was</th>\n",
       "      <td>974</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      count\n",
       "the    4053\n",
       "and    2875\n",
       "i      2728\n",
       "of     2537\n",
       "to     1965\n",
       "my     1666\n",
       "a      1311\n",
       "in     1067\n",
       "that   1013\n",
       "was     974"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sorting by count\n",
    "df = df.sort_values(by=['count'], ascending = False)\n",
    "\n",
    "#printing the first ten lines\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected from most English text the word \"the\" is the most common. This also confirms that we did a good job with the statistics.\n",
    "\n",
    "We are now required to print mean and median of the word counts. Using `pandas` methods this is a trivial task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    10.361745\n",
       "dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    2.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's quite a difference: the mean is five times the median value! This is certainly a skewed distribution, with very few words appearing a high number of times and many many rare words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next steps...\n",
    "\n",
    "This concludes our task. In this exercise we've worked with lists, dictionaries, dataframes, zip archives, remote and local files, and strings. We built a solid solution but there's always room for improvement. Consider:\n",
    "\n",
    "- how to improve word splitting? Currently hyphened-words are fused...\n",
    "- maybe apostrophes deserve a special status? For example \"what's\" should be considered as two separated words, not as \"whats\"\n",
    "- it would be nice to plot an histogram of word frequencies using [matplotlib.pyplot.hist](https://matplotlib.org/3.2.2/api/_as_gen/matplotlib.pyplot.hist.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
