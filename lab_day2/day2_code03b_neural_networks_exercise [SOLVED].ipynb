{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"day2_code04d_neural_networks_exercise [SOLVED].ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMXN10AcSLfJh2LGxnxEfjQ"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"Yt_A6nW4nnWl"},"source":["## Neural networks models: practicals\n","\n","In this notebook you will practice simple neural networks models for classification. \n","We will be using the `breast cancer` dataset:\n","\n","- binary classification problem: breast cancer diagnosis, `0`: `malignant`, `1`: `benign`\n","- EDA: look at the data\n","- split between the training and the test sets\n","- number of hidden layers\n","- number of nodes within layers\n","- type of activation functions in the hidden layers\n","- number of epochs\n","- number of features to include in the model\n","- etc.\n","\n","Let's start by importing some basic libraries and the data:"]},{"cell_type":"code","metadata":{"id":"zec9A2Dzm6QO"},"source":["## import libraries\n","import numpy as np\n","import tensorflow as tf\n","import pandas as pd\n","import sklearn.datasets\n","import matplotlib.pyplot as plt"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vs_c5og5oklW"},"source":["\n","## Breast cancer data\n","\n","Now, it's up to you to continue: write here your code!! (plus text chunks for explanations)"]},{"cell_type":"code","metadata":{"id":"fKOxluEnn7Kz"},"source":["from sklearn.datasets import load_breast_cancer\n","bcancer = load_breast_cancer()\n","y = bcancer.target\n","X = bcancer.data\n","y.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Hrqq466ezgjs"},"source":["from collections import Counter\n","print(Counter(y))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VpLvqpI2qSaG"},"source":["print(bcancer.DESCR)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QOwqolFYL5-e"},"source":["### Explore the data"]},{"cell_type":"code","metadata":{"id":"jQ4nrTezz9ub"},"source":["bcancer.data = pd.DataFrame(bcancer.data, columns=bcancer.feature_names) #converting numpy array -> pandas DataFrame\n","bcancer.target = pd.Series(bcancer.target)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6Nf7wTpW1LXY"},"source":["features = bcancer.data.iloc[:,:]\n","target = bcancer.target\n","features"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7J4XGVk7r2JX"},"source":["#we want to have the same proportion of classes in both train and validation sets\n","from sklearn.model_selection import StratifiedShuffleSplit\n","\n","#building a StratifiedShuffleSplit object (sss among friends) with 20% data\n","#assigned to validation set (here called \"test\")\n","sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=0)\n","\n","#the .split() method returns (an iterable over) two lists which can be\n","#used to index the samples that go into train and validation sets\n","for train_index, val_index in sss.split(features, target):\n","    X_train = features.iloc[train_index, :]\n","    X_val   = features.iloc[val_index, :]\n","    y_train   = target[train_index]\n","    y_val     = target[val_index]\n","    \n","#let's print some shapes to get an idea of the resulting data structure\n","print(\"Training features size: \", X_train.shape)\n","print(\"Test features size: \", X_val.shape)\n","print(\"Training targets size: \", y_train.shape)\n","print(\"Test targets size: \", y_val.shape)\n","\n","print(\"Type of the training features object: \", type(X_train))\n","print(\"Type of the training targets object: \", type(y_train))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9pkijw8ksdF5"},"source":["## # Configuration options\n","input_shape = (X_train.shape[1],) ## tuple that specifies the number of features \n","hidden_nodes = 16\n","hidden_activation = 'relu'\n","output_activation = 'sigmoid'\n","loss_function = 'binary_crossentropy'\n","optimizer_used = 'sgd' ##stochastic gradient descent\n","num_epochs = 100\n","\n","print(input_shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Fg89DFRBsil8"},"source":["from keras.models import Sequential\n","from keras.layers import Dense ## a \"dense\" layer is a layer were all the data coming in are connected\n","#to all nodes.\n","\n","# binary classification shallow neural network model in Keras\n","model = Sequential()\n","model.add(Dense(units=hidden_nodes, input_shape=input_shape, activation=hidden_activation))\n","model.add(Dense(1, activation=output_activation))\n","\n","#the model is declared, but we still need to compile it to actually\n","#build all the data structures\n","model.compile(optimizer=optimizer_used, loss=loss_function)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9tyCBVxlstZ1"},"source":["print(model.summary())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"d9vFz7tqs3Nt"},"source":["history = model.fit(X_train, y_train, epochs=num_epochs, validation_data=(X_val, y_val), verbose=0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ACO_-lrytDMJ"},"source":["def plot_loss_history(h, title):\n","    plt.plot(h.history['loss'], label = \"Train loss\")\n","    plt.plot(h.history['val_loss'], label = \"Validation loss\")\n","    plt.xlabel('Epochs')\n","    plt.title(title)\n","    plt.legend()\n","    plt.show() \n","\n","plot_loss_history(history, 'Logistic ({} epochs)'.format(num_epochs))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0h2U3HKstfZ6"},"source":["from sklearn.metrics import confusion_matrix\n","\n","predictions = model.predict(X_val)\n","predicted_labels = np.where(predictions > 0.5, \"benign\", \"malignant\")\n","target_labels = y_val.to_numpy().reshape((len(y_val),1))\n","target_labels = np.where(target_labels > 0.5, \"benign\", \"malignant\")\n","\n","con_mat_df = confusion_matrix(target_labels, predicted_labels, labels=[\"malignant\",\"benign\"])\n","print(con_mat_df)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0uMJ7ZGHtM2C"},"source":["### Data normalization"]},{"cell_type":"code","metadata":{"id":"KCtHCXavMhh-"},"source":["features.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-ztEYiPBtPeb"},"source":["#getting an idea about features averages, sd\n","avg = X_train.mean()\n","std = X_train.std()\n","print('Feature means')\n","print(avg)\n","print('\\nFeature standard deviations')\n","print(std)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"d9VfgbRptZDc"},"source":["#IMPORTANT: normalizing features using the same weights for both\n","#train and validation test (which are computed ON THE TRAIN SET)\n","X_train = (X_train - avg)/std\n","X_val = (X_val - avg)/std"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JHsFr2xj2Mi7"},"source":["X_train"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xxDQZsmd2ZfH"},"source":["## # Configuration options\n","input_shape = (X_train.shape[1],) ## tuple that specifies the number of features \n","hidden_nodes = 16\n","hidden_activation = 'relu'\n","output_activation = 'sigmoid'\n","loss_function = 'binary_crossentropy'\n","optimizer_used = 'sgd' ##stochastic gradient descent\n","num_epochs = 100"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5gJwSNCF2scZ"},"source":["#we are building a \"sequential\" model, meaning that the data will \n","#flow like INPUT -> ELABORATION -> OUTPUT.\n","from keras.models import Sequential\n","\n","#a \"dense\" layer is a layer were all the data coming in are connected\n","#to all nodes.\n","from keras.layers import Dense\n","\n","# binary classification shallow neural network model in Keras\n","model = Sequential()\n","model.add(Dense(units=hidden_nodes, input_shape=input_shape, activation=hidden_activation))\n","model.add(Dense(1, activation=output_activation))\n","\n","#the model is declared, but we still need to compile it to actually\n","#build all the data structures\n","model.compile(optimizer=optimizer_used, loss=loss_function)\n","model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"C2zBp1ej2fOT"},"source":["history = model.fit(X_train, y_train, epochs=num_epochs, validation_data=(X_val, y_val), verbose=0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TRS6zVke21PH"},"source":["plot_loss_history(history, 'Logistic ({} epochs)'.format(num_epochs))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WEZLODEO27vU"},"source":["predictions = model.predict(X_val)\n","predicted_labels = np.where(predictions > 0.5, \"cancer\", \"no-cancer\")\n","target_labels = y_val.to_numpy().reshape((len(y_val),1))\n","target_labels = np.where(target_labels > 0.5, \"cancer\", \"no-cancer\")\n","\n","con_mat_df = confusion_matrix(target_labels, predicted_labels, labels=[\"no-cancer\",\"cancer\"])\n","print(con_mat_df)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EpXslUr9sfTO"},"source":["history2 = model.fit(X_train, y_train, epochs=100, \n","                     validation_data=(X_val, y_val), verbose=0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0iN8RHwWsQCr"},"source":["#putting together the whole history\n","history.history['loss'] += history2.history['loss']\n","history.history['val_loss'] += history2.history['val_loss']\n","\n","#and plotting again\n","plot_loss_history(history, 'Logistic (500 epochs)')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yhL1mZAb3JNb"},"source":["predictions = model.predict(X_val)\n","predicted_labels = np.where(predictions > 0.5, \"cancer\", \"no-cancer\")\n","target_labels = y_val.to_numpy().reshape((len(y_val),1))\n","target_labels = np.where(target_labels > 0.5, \"cancer\", \"no-cancer\")\n","\n","con_mat_df = confusion_matrix(target_labels, predicted_labels, labels=[\"no-cancer\",\"cancer\"])\n","print(con_mat_df)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uDDXxNOh3Obb"},"source":["model = Sequential()\n","model.add(Dense(units=hidden_nodes, input_shape=input_shape, activation=hidden_activation))\n","model.add(Dense(units=hidden_nodes, input_shape=input_shape, activation=hidden_activation))\n","model.add(Dense(1, activation=output_activation))\n","\n","#the model is declared, but we still need to compile it to actually\n","#build all the data structures\n","model.compile(optimizer=optimizer_used, loss=loss_function)\n","model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZtC-mQFe3agS"},"source":["history = model.fit(X_train, y_train, epochs=num_epochs, validation_data=(X_val, y_val), verbose=0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cIdfl23B3eiM"},"source":["plot_loss_history(history, 'Breast cancer data (100 epochs)')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z0HrDNLE3kuf"},"source":["predictions = model.predict(X_val)\n","predicted_labels = np.where(predictions > 0.5, \"cancer\", \"no-cancer\")\n","target_labels = y_val.to_numpy().reshape((len(y_val),1))\n","target_labels = np.where(target_labels > 0.5, \"cancer\", \"no-cancer\")\n","\n","con_mat_df = confusion_matrix(target_labels, predicted_labels, labels=[\"no-cancer\",\"cancer\"])\n","print(con_mat_df)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aW7OQRgwr55s"},"source":["import seaborn as sn\n","\n","figure = plt.figure(figsize=(8, 8))\n","sn.heatmap(con_mat_df, annot=True,cmap=plt.cm.Blues)\n","plt.tight_layout()\n","plt.ylabel('True label')\n","plt.xlabel('Predicted label')\n","plt.show()"],"execution_count":null,"outputs":[]}]}