{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "A7KaVFHlxb1n"
      ]
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A7KaVFHlxb1n"
      },
      "source": [
        "# Logistic regression\n",
        "\n",
        "We are going to do [logistic regression](https://en.wikipedia.org/wiki/Logistic_regression) on the famous [Iris dataset](https://en.wikipedia.org/wiki/Iris_flower_data_set) using a neural network-like implementation, and plot the decision boundary."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wL33hK2-xb1t"
      },
      "source": [
        "# Setup\n",
        "The topics of this exercise are very famous and very well known, so a lot of educational material is available online. E.g., for logistic regression:\n",
        "\n",
        "* [Logistic regression @towardsdatascience](https://towardsdatascience.com/understanding-logistic-regression-9b02c2aec102)\n",
        "* [Logistic regression @Biochemia Medica](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3936971/)\n",
        "* [Logistic regression @datacamp](https://www.datacamp.com/community/tutorials/understanding-logistic-regression-python)\n",
        "\n",
        "Let's just frame the terms of the first part of the problem:\n",
        "* we are talking about **binary** classification: all samples belong to two classes (represented by values 0 and 1). We want to build a statistical machine able to predict, for a new sample, the class\n",
        "* for each sample we have a set of numbers, called **features**. The easiest-to-understand case is when these features are actual phyisical measurements, but any set of data will do\n",
        "* in **standard regression** we weight each feature with a number (positive or negative, big or small). We then multiply each feature times its weight and add everything...\n",
        "* ...but we cannot do that now, since the resulting number could be very big (positive big or negative big). But our desired result is a class! In other words our machine needs to produce either a zero or a one. Or maybe **all the numbers between zero and one**, so that we have an idea about how certain our prediction is\n",
        "* in fact, a 0.99 will show more confidence than a 0.8, which will give more confidence than a 0.65, even if all three outputs at the end can be considered as \"class 1\" (since those numbers are closer to 1 than to 0)\n",
        "* to do so we feed what is produced by a regular regression into a **sigmoid function**, which looks like this:\n",
        "\n",
        "<img src=\"https:///raw.githubusercontent.com/ne1s0n/coding_excercises/master/data/Logistic-curve.png\" width=\"400\">\n",
        "\n",
        "This function takes in input any number from -infinity to +infinity and returns a value between zero and one. This will be our prediction. Let's start building the solution."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vQrrKeGYxb1y"
      },
      "source": [
        "## Loading libraries and setting the random seed\n",
        "\n",
        "First of all, we load some necessary libraries; then we setup the random seed to ensure reproducibility of results. Since tensorflow uses an internal random generator we need to fix both the general seed (via numpy `seed()`) and tensorflow seed (via `set_seet()`)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AjF5SK5bxb13"
      },
      "source": [
        "#libraries\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJAAk3xln5xn"
      },
      "source": [
        "## setting seeds\n",
        "from numpy.random import seed\n",
        "seed(131)\n",
        "\n",
        "import tensorflow as tf\n",
        "#tf.random.set_seed(777)\n",
        "tf.keras.utils.set_random_seed(10)\n",
        "tf.config.experimental.enable_op_determinism()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FL2D56dZxb2S"
      },
      "source": [
        "# The Iris dataset\n",
        "\n",
        "The dataset we are going to use is very famous. It was published by Robert Fisher in 1936 together with the paper [The use of multiple measurements in taxonomic problems](https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1469-1809.1936.tb02137.x). Data are public and nowadays this dataset is shipped with many statistical software and packages. We are going to use the copy coming with [sci-kit learn](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_iris.html#sklearn.datasets.load_iris)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n6OEdjz75uvF"
      },
      "source": [
        "First of all, let's verify the sci-kit version available:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NV2m-K3i51Mg"
      },
      "source": [
        "import sklearn.datasets\n",
        "print(sklearn.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gU1rz0C852xM"
      },
      "source": [
        "From version 0.23+ we can simply do:\n",
        "\n",
        "> `iris = sklearn.datasets.load_iris(return_X_y = True, as_frame = True)`"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#iris = sklearn.datasets.load_iris(return_X_y=True, as_frame=True)\n",
        "#print(iris[1])"
      ],
      "metadata": {
        "id": "ogr7kcByj6Td"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The main difference is in the format used to store data: numpy array (version 0.22 and below) or pandas dataframe/series (version 0.23 and above).\n",
        "To make sure we use the pandas data structure, we can apply the following little conversion (instead of relying on a higher level function):"
      ],
      "metadata": {
        "id": "qVUDRY8vLsWn"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVnTo-17xb2V"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "iris = sklearn.datasets.load_iris()\n",
        "iris.data = pd.DataFrame(iris.data, columns=iris.feature_names) #converting numpy array -> pandas DataFrame\n",
        "iris.target = pd.Series(iris.target) #converting numpy array -> pandas Series"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kxHM6By7xb2q"
      },
      "source": [
        "The variable `iris` is now a [bunch object](https://scikit-learn.org/stable/modules/generated/sklearn.utils.Bunch.html#sklearn.utils.Bunch) and contains all the required data (via `attributes`: `.data`, `.target`; also with the commented-out syntax above we'd get a bunch object, via indexes `[0]`, `[1]`)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1YWPwTcxb2u"
      },
      "source": [
        "#uncomment the following instruction to print a detailed description\n",
        "#of the Iris dataset, here omitted for compactness\n",
        "print(iris.DESCR)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JsHRYaXSxb2_"
      },
      "source": [
        "The dataset describes 150 flower samples, belonging to three species of Iris (Iris setosa, Iris virginica and Iris versicolor). Four features were measured from each sample: the length and the width of the sepals and of the petals, in centimeters. Features are found in the attribute `.data` of the returned bunch object:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efNZU1tDxb3D"
      },
      "source": [
        "print('Shape of the feature table: ' + str(iris.data.shape))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0PFAyC0Vxb3X"
      },
      "source": [
        "We can take a look at the actual numbers:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63lQd2Pnxb3a"
      },
      "source": [
        "print(iris.data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XNIsHxs8xb3w"
      },
      "source": [
        "As said above, each of the 150 lines represents a different flower, each belonging to one of the three Iris species. The species will be our target, the class that we are trying to predict. Let's take a look into the dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uBK_Kec4xb3y"
      },
      "source": [
        "print('Shape of the target variable: ' + str(iris.target.shape))\n",
        "print('Names for each class: ' + str(iris.target_names))\n",
        "\n",
        "#using Counter object to print a tally of the classes\n",
        "from collections import Counter\n",
        "print('Numerosity for each class: ' + str(Counter(iris.target)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9unw7Ck6xb3_"
      },
      "source": [
        "Classes are represented via a numeric index: 0 for *setosa*, 1 for *versicolor*, 2 for *virginica*. The samples are presented in order, with the first 50 samples being *setosa*, then 50 *versicolor* and the last 50 being *virginica*.\n",
        "\n",
        "Always when working with a new datasets it is importat to plot the data if possible. We are unfortunately talking about a 5-dimensional dataset (the four features + the target class) which is not easily representable. One solution in these cases is to slice a subset of the whole dataset.\n",
        "\n",
        "In the following code we'll plot two features at a time, plus the class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JXcYoGlDxb4B"
      },
      "source": [
        "#change these two values to plot different features, remembering the numbering:\n",
        "# 0 : sepal length (cm)\n",
        "# 1 : sepal width (cm)\n",
        "# 2 : petal length (cm)\n",
        "# 3 : petal width (cm)\n",
        "feature_x = 0\n",
        "feature_y = 1\n",
        "\n",
        "#old reliable pyplot!\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#starting a new plot\n",
        "fig, ax = plt.subplots()\n",
        "\n",
        "#adding data in three bunches of 50, once per class\n",
        "ax.scatter(x=iris.data.iloc[0:50,feature_x],    y=iris.data.iloc[0:50,feature_y],    c='red',   label=iris.target_names[0])\n",
        "ax.scatter(x=iris.data.iloc[50:100,feature_x],  y=iris.data.iloc[50:100,feature_y],  c='green', label=iris.target_names[1])\n",
        "ax.scatter(x=iris.data.iloc[100:150,feature_x], y=iris.data.iloc[100:150,feature_y], c='blue',  label=iris.target_names[2])\n",
        "\n",
        "#the axis names are taken from feature names\n",
        "ax.set_xlabel(iris.feature_names[feature_x])\n",
        "ax.set_ylabel(iris.feature_names[feature_y])\n",
        "\n",
        "#adding the legend and printing the plot\n",
        "ax.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8gLUzs_Axb4R"
      },
      "source": [
        "The plot shows clearly that setosa is quite separate from the other two classes. Even chosing other features for the plot the general result is similar.\n",
        "\n",
        "To be totally frank, this dataset is quite simple. In fact even if it's not possible to easily plot everything, using the four features most classifier can reach very close to 100% accuracy when trying to separate Setosa from the other species.\n",
        "\n",
        "To make things a little more interesting we decide to **renounce to half of our features**, **using only the first two** columns. Moreover, we **join together Setosa and Versicolor**. In other words, we want a classifier able to discriminate virginica (which becomes the new class \"1\") from the other irises (which all together become the new class \"0\"):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKlFTUZkxb4U"
      },
      "source": [
        "#simplifly the problem: less classes, less features\n",
        "features = iris.data.iloc[:, 0:2]\n",
        "target = iris.target\n",
        "\n",
        "#updating class labels. To makes things difficult we put together old classes 0 and 1\n",
        "#in a new class (non virginica) and keep old class 2 (virginica) as new class 1.\n",
        "#For an easier problems put together versicolor and virginica and keep setosa by itself\n",
        "j = 100 ## split: 50 for setosa vs versicolor+virginica, 100 for setosa+versicolor vs virginica\n",
        "target[0:j] = 0\n",
        "target[j:150] = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "poFrOjYtxb4j"
      },
      "source": [
        "Let's take a look at the new dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TA53hyylxb4m"
      },
      "source": [
        "#starting a new plot\n",
        "fig, ax = plt.subplots()\n",
        "\n",
        "#adding data in two bunches\n",
        "ax.scatter(x=features.iloc[0:j,0],   y=features.iloc[0:j,1],   c='red',  label='Not virginica')\n",
        "ax.scatter(x=features.iloc[j:150,0], y=features.iloc[j:150,1], c='blue', label='virginica')\n",
        "\n",
        "#the axis names are taken from feature names\n",
        "ax.set_xlabel(iris.feature_names[feature_x])\n",
        "ax.set_ylabel(iris.feature_names[feature_y])\n",
        "\n",
        "#adding the legend and printing the plot\n",
        "ax.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ZJ8LK-oxb41"
      },
      "source": [
        "Things are getting interesting! This is now a difficult problem and there is no clear cut solution. Let's proceed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tC1QwVSkxb44"
      },
      "source": [
        "# Training and validation sets\n",
        "\n",
        "Each time there is some kind of \"learning\" involved we need to split our data. A subset will be used for training, and a subset will be used for validation. (there may be room for another subset, the \"test set\", but we are not talking about it now).\n",
        "\n",
        "In our current dataset the samples are sorted by class: the first 100 are from \"Not virginica\" class, and the remaining 50 are from virginica. We want to keep this 2:1 proportion (roughly) the same in both train and validation set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8T2IV-Yxb48"
      },
      "source": [
        "#selecting the first 100 samples for training would be a bad choice...\n",
        "print(Counter(iris.target[0:100]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fr9IavcXxb5M"
      },
      "source": [
        "To do so we are going to use what is called a [stratified approach](https://machinelearningmastery.com/cross-validation-for-imbalanced-classification/) using a [StratifiedShuffleSplit](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedShuffleSplit.html) object from Sci-kit learn:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUfSZFZCxb5Q"
      },
      "source": [
        "#we want to have the same proportion of classes in both train and validation sets\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "\n",
        "#building a StratifiedShuffleSplit object (sss among friends) with 20% data\n",
        "#assigned to validation set (here called \"test\")\n",
        "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=0)\n",
        "\n",
        "#the .split() method returns (an iterable over) two lists which can be\n",
        "#used to index the samples that go into train and validation sets\n",
        "for train_index, val_index in sss.split(features, target):\n",
        "    features_train = features.iloc[train_index, :]\n",
        "    features_val   = features.iloc[val_index, :]\n",
        "    target_train   = target[train_index]\n",
        "    target_val     = target[val_index]\n",
        "\n",
        "#let's print some shapes to get an idea of the resulting data structure\n",
        "print(features_train.shape)\n",
        "print(features_val.shape)\n",
        "print(target_train.shape)\n",
        "print(target_val.shape)\n",
        "\n",
        "print(type(features_train))\n",
        "print(type(target_train))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features_train.head()"
      ],
      "metadata": {
        "id": "_9kgwWpeReSd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZMFdrCCDxb5b"
      },
      "source": [
        "It appears that we are using 20% of our data (30 out of 150) for the validation set and the other 80% for the train set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8CFbA8utsoe"
      },
      "source": [
        "print(Counter(target_train))\n",
        "print(Counter(target_val))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yW3iFteCxb5c"
      },
      "source": [
        "# Logistic regression using Keras\n",
        "\n",
        "While most statistical packets implement some form of logistic regression in this exercise we are interested in using Keras, which is a library aimed to (Deep) Neural Networks.  \n",
        "Actually logistic regression plays an important role in neural networks and it's typically used in the last (or second to last) layer of a classifier. For more details on how to use keras a good starting point is the [documentation on training and evaluation](https://www.tensorflow.org/guide/keras/train_and_evaluate).\n",
        "\n",
        "Our neural network will be very easy and very minimal, and will be comprised of only one node (neuron) implementing both regression (linear combination of weighted input variables + bias term) and sigmoid function.\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/ne1s0n/coding_excercises/master/data/sigmoid_neuron.png\">\n",
        "\n",
        "We are now ready to build the model!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "za3grH4qWDlS"
      },
      "source": [
        "### Model set-up"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_g85kX5MV2Fj"
      },
      "source": [
        "activation_function = 'sigmoid'\n",
        "optimizing_method = 'rmsprop'\n",
        "loss_function = 'binary_crossentropy'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FU9nDLYPxb5f"
      },
      "source": [
        "#we are building a \"sequential\" model, meaning that the data will\n",
        "#flow like INPUT -> ELABORATION -> OUTPUT. In particular, we will\n",
        "#not have any loops, i.e. our output will never be recycled as\n",
        "#input for the first layer\n",
        "from keras.models import Sequential\n",
        "\n",
        "#a \"dense\" layer is a layer were all the data coming in are connected\n",
        "#to all nodes. In our case there is only one node in the layer, and\n",
        "#it receives all the features\n",
        "from keras.layers import Dense\n",
        "\n",
        "# 2-class logistic regression in Keras\n",
        "model = Sequential()\n",
        "model.add(Dense(1, activation='sigmoid', input_dim=features_train.shape[1]))\n",
        "\n",
        "#the model is declared, but we still need to compile it to actually\n",
        "#build all the data structures\n",
        "model.compile(optimizer=optimizing_method, loss=loss_function)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yuefLP5OiuM1"
      },
      "source": [
        "Let's take a look inside the model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vhg73fdLiu8k"
      },
      "source": [
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6wKy6S8Hi6wY"
      },
      "source": [
        "Keras informs us that there are three trainable parameters (W1, W2, B), and a single node. The output is a single number. Excellent."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9soWAxvoxb5v"
      },
      "source": [
        "We have now prepared everything we need and are ready to train the model on our data. It's an iterative process that cycles many times through what are called `epochs`. We'll start with ten:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-B5xRokaxb5x"
      },
      "source": [
        "history = model.fit(features_train, target_train, epochs=10, validation_data=(features_val, target_val))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yaPQ3qYUxb59"
      },
      "source": [
        "We asked for ten epochs and the network did just that. At each iteration the network is trying really hard to minimize a [value called \"loss\"](https://keras.io/api/losses/). The specifics are defined by our choice of loss function (we selected `binary_crossentropy`). The basic idea is that the smaller the loss the better the fit.\n",
        "\n",
        "Note that the network minimizes the loss on the training set and does not use the validation set during the learning process. It can however measure the loss on the validation set to give us an idea on how well it can generalize on new data.\n",
        "\n",
        "It's handy at this point to define a function that takes in the `history` object returned by `.fit()` and plots it:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XfH-PParxb5_"
      },
      "source": [
        "#function to take a look at losses evolution\n",
        "def plot_loss_history(h, title):\n",
        "    plt.plot(h.history['loss'], label = \"Train loss\")\n",
        "    plt.plot(h.history['val_loss'], label = \"Validation loss\")\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.title(title)\n",
        "    plt.legend()\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DlPjVxmRxb6L"
      },
      "source": [
        "plot_loss_history(history, 'Logistic (10 epochs)')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i9tBexuixb6Z"
      },
      "source": [
        "The good news is that loss just goes down, both in train and validation set. We can keep training - without recompiling, we just add new epochs to our network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8y9EPqsAxb6b"
      },
      "source": [
        "#putting verbose to 0 to avoid filling the screen\n",
        "history2 = model.fit(features_train, target_train, epochs=190,\n",
        "                     validation_data=(features_val, target_val), verbose=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ZZ8CsP5xb6j"
      },
      "source": [
        "Let's see if we improved:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83sq7AIrxb6m"
      },
      "source": [
        "#putting together the whole history\n",
        "history.history['loss'] += history2.history['loss']\n",
        "history.history['val_loss'] += history2.history['val_loss']\n",
        "\n",
        "#and plotting again\n",
        "plot_loss_history(history, 'Logistic (500 epochs)')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2lYDLDzxb6y"
      },
      "source": [
        "This is very informative: losses keep shrinking, meaning that the network keeps improving. However after a first phase of steep improvement the gain for each epoch slows down considerably.\n",
        "\n",
        "Moreover, we now see a clear difference between train and validation set. This means that, while the network keeps improving, its performances on new data are expected to be worse than those on the training data.\n",
        "\n",
        "Now, we could ask: what happens if we keep training for a long time? We have prepared the code for 10000 epochs, but it takes a long time to run, and it's faster if we simply show the saved results (but you can try to run it putting the following flag to `True`):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQToxteexb65"
      },
      "source": [
        "do_10000_epochs = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XFlo_sxwxb7J"
      },
      "source": [
        "#what happens if we keep going for a (very) long time?\n",
        "if (do_10000_epochs):\n",
        "    #train for 10000 epochs, just to show how the model evolves\n",
        "    history3 = model.fit(features_train, target_train, epochs=9500,\n",
        "                         validation_data=(features_val, target_val), verbose=0)\n",
        "\n",
        "    #putting together the whole history\n",
        "    history.history['loss'] += history3.history['loss']\n",
        "    history.history['val_loss'] += history3.history['val_loss']\n",
        "\n",
        "    #and plotting again\n",
        "    plot_loss_history(history, 'Logistic (10000 epochs)')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4AUuYZfExb7X"
      },
      "source": [
        "Our pre-recorded results look like this:\n",
        "\n",
        "![regression_10000_epochs](https://raw.githubusercontent.com/ne1s0n/coding_excercises/master/data/regression_loss10000.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQ8weW9axb7Z"
      },
      "source": [
        "It appears that there is constant, slow improvement on training set. Improvement on validation set is slower, and if we had the patience to go for a veeeery long time the orange curve would become completely flat."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nPLcmwSpxb7d"
      },
      "source": [
        "# Decision Boundary\n",
        "\n",
        "The assignment asks us to plot the [decision boundary](https://en.wikipedia.org/wiki/Decision_boundary), i.e. a representation in the feature space of the criterions the model is using to classify your data. For this task we'll use the [mlxtend module](http://rasbt.github.io/mlxtend/), which unfortunately does not come with the standard installation. Let's add it!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XDOY48G31hO-"
      },
      "source": [
        "!pip install mlxtend ##execute shell command"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YSlW8Zn62TFT"
      },
      "source": [
        "We can now import `mlxtend` package safely."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IcNiGJoCxb7f"
      },
      "source": [
        "from mlxtend.plotting import plot_decision_regions\n",
        "\n",
        "#we'll print the training set\n",
        "plot_decision_regions(X = features_train.to_numpy(), y = target_train.to_numpy(), clf=model)\n",
        "plt.title('Decision boundary for 0 (non virginica) vs 1 (virginica)')\n",
        "plt.xlabel(iris.feature_names[feature_x])\n",
        "plt.ylabel(iris.feature_names[feature_y])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dSVGzjaLxb70"
      },
      "source": [
        "The decision boundary is linear, as expected by logistic regression. This means that all samples in the pink area will be classified as 1 (virginica) and all points in the blue area be considered 0 (non virginica).\n",
        "\n",
        "Note that relatively many virginica samples are in the blue area compared to the numer of non-virginica present in the pink area. Also note that, roughly speaking, the regressor assigned a wider area to non-virginica. This is a direct consequence of having an unbalanced dataset: two-thirds of the samples are non-virginica (blue squares) and one-third are virginica (red triangles). **The resulting regressor is polarised** toward the more numerous class."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6VERgAx6xb71"
      },
      "source": [
        "# Actual predictions\n",
        "\n",
        "Any model is only useful when it's used to predict new, unknown data. In fact the whole validation set was put apart and not really used for training for this specific reason.\n",
        "\n",
        "Luckily, it's very easy to apply a trained model to new values via the [predict() method](https://keras.io/api/models/model_training_apis/#predict-method).\n",
        "\n",
        "**Question for you: what do these predictions (below) represent?**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h9Qx8SZIxb73"
      },
      "source": [
        "predictions = model.predict(features_val)\n",
        "print(predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQQhWl_1xb8E"
      },
      "source": [
        "We can now compare the list of prediction (sometimes called Ŷ) with the true classes from our validation set (sometimes called Y)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fSRwtXesxb8F"
      },
      "source": [
        "#starting a new plot\n",
        "fig, ax = plt.subplots()\n",
        "\n",
        "#adding data in two bunches\n",
        "ax.scatter(x=range(30), y=predictions, c='red',  label='predictions')\n",
        "ax.scatter(x=range(30), y=target_val,  c='blue', label='true classes')\n",
        "\n",
        "#adding a horizontal line at quote 0.5, to represent the decision boundary\n",
        "ax.hlines(y=0.5, xmin=0, xmax=29, colors='black')\n",
        "\n",
        "#adding the legend and printing the plot\n",
        "ax.legend(loc='upper right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4I7di12sxb8r"
      },
      "source": [
        "Note that the vast majority of predictions is below the 0.5 line (recall that the closer a prediction is to 0 or to 1 the higher the prediction confidence).\n",
        "\n",
        "This confirms our suspicions: the regressor prefers to assign new data to the 0 (non virginica) class.\n",
        "\n",
        "Below, we use the **0.5 threshold** to assign samples to the two classes (0 $\\rightarrow$ `non-virginica`; 1 $\\rightarrow$ `virginica`.\n",
        "\n",
        "Then, we compare predicted and true classes in the test set\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s1ZdFJYgIk5y"
      },
      "source": [
        "predicted_class = np.where(predictions > 0.5, \"virginica\", \"non-virginica\")\n",
        "target_class = np.where(target_val == 1, \"virginica\", \"non-virginica\")\n",
        "target_class = target_class.reshape(len(target_class),1)\n",
        "\n",
        "results = target_class == predicted_class\n",
        "\n",
        "unique, counts = np.unique(results, return_counts=True)\n",
        "print(\"\\nN. of mismatches (0s) and matches (1s): \")\n",
        "print(np.asarray((unique, counts)).T)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8CdVvCmWRpWw"
      },
      "source": [
        "From the number of **matches** (`True` comparison $\\rightarrow$ 1s) and **mismatches** (`False` comparison $\\rightarrow$ 0s) we can calculate the total **error rate**:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6gOmROCRaRw"
      },
      "source": [
        "if len(counts) > 1:\n",
        "   n_matches = counts[1]\n",
        "   n_mismatches = counts[0]\n",
        "else:\n",
        "  n_matches = counts[0]\n",
        "  n_mismatches = 0\n",
        "\n",
        "error_rate = n_mismatches/(n_mismatches+n_matches)\n",
        "print(\"Error rate is: {:.2f}\".format(round(error_rate,4)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SF_n337ZZw3H"
      },
      "source": [
        "From the error rate we can derive the **overall accuracy**, by simply taking `1 - error rate`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XI9zs5BLZ5AH"
      },
      "source": [
        "print(\"Accuracy is: \", 1 - error_rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iW2V_BmH0aMA"
      },
      "source": [
        "#### Confusion matrix\n",
        "\n",
        "Besides the overall error rate, we need to look at the accuracy in the subclasses. This is especially important when data are unbalanced. We can have a more comprehensive assessment of the performance of a classification model by looking at the <a href=\"https://en.wikipedia.org/wiki/Confusion_matrix\">confusion matrix</a>.\n",
        "\n",
        "Let's start by looking closer at the vectors of observed and predicted labels:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target_class[0:5]"
      ],
      "metadata": {
        "id": "JC9UC6Jolfn8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.unique(target_class, return_counts=True)"
      ],
      "metadata": {
        "id": "C_MORRL6jwXD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_class[0:5]"
      ],
      "metadata": {
        "id": "hvLtOPJmlkJq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S9MGIXjiQNqK"
      },
      "source": [
        "np.unique(predicted_class, return_counts=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we are ready to build and examine our **confusion matrix**:"
      ],
      "metadata": {
        "id": "n9cF0KvQlwge"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ceeui_mD06cl"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "labels = ['non-virginica','virginica']\n",
        "con_mat_df = confusion_matrix( y_true = target_class, y_pred = predicted_class, labels=labels) #true are rows, predicted are columns\n",
        "pd.DataFrame(\n",
        "    con_mat_df,\n",
        "    index = ['true:'+x for x in labels],\n",
        "    columns = ['pred:'+x for x in labels])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question for you: from the above results, how do we calculate the TPR?**"
      ],
      "metadata": {
        "id": "kL15zo9bJ5Pn"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "juKrvxaXxb8t"
      },
      "source": [
        "# Exercise: do it yourself! (optional)\n",
        "\n",
        "In the above illustration we used one keras node with sigmoid activation function to perform logistic regression on a binarised version (two classes) of the `Iris` dataset. Only two features were used.\n",
        "\n",
        "It is now time for you to try write your own code!\n",
        "\n",
        "There are several things that can be tried as variations on the above code:\n",
        "\n",
        "* what is the effect of including the other two features, that we excluded above? Does performance improve? What happens to decision boundary?\n",
        "* when implementing the network we used [rmsprop optimizer](https://keras.io/api/optimizers/rmsprop/) and [binary_crossentropy](https://keras.io/api/losses/probabilistic_losses/#binarycrossentropy-class) loss function, but other [optimizers](https://keras.io/api/optimizers/) and [loss functions](https://keras.io/api/losses/) are available and their effect could be explored\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We first set the path (get the data and do a little preprocessing). Then we'll tackle each step separately: first on your own, then together."
      ],
      "metadata": {
        "id": "cvi5NPA7xcx4"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Wp58GHWE1Lb"
      },
      "source": [
        "iris = sklearn.datasets.load_iris()\n",
        "iris.data = pd.DataFrame(iris.data, columns=iris.feature_names) #converting numpy array -> pandas DataFrame\n",
        "iris.target = pd.Series(iris.target) #converting numpy array -> pandas Series"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QxZ3kcydCrjG"
      },
      "source": [
        "features = iris.data\n",
        "target = iris.target"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-lihQB0aC8ju"
      },
      "source": [
        "features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mKGBIY5kC8hb"
      },
      "source": [
        "j = 100 ## split\n",
        "target[0:j] = 0  ## non-virginica\n",
        "target[j:150] = 1 ## virginica"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQMlov8KDSoq"
      },
      "source": [
        "np.unique(target, return_counts=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Feature normalization?\n",
        "\n",
        "How would you do it?"
      ],
      "metadata": {
        "id": "vOui_-edcqtX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## your code here"
      ],
      "metadata": {
        "id": "VmHRyffKcpsW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training and validation sets\n",
        "\n",
        "Define your split"
      ],
      "metadata": {
        "id": "cgPtjegogCsr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## your code here"
      ],
      "metadata": {
        "id": "rx9yZOkbgGJz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Configuration of (hyper)parameters\n",
        "\n",
        "Set your parameters"
      ],
      "metadata": {
        "id": "rBhLZvLPgOR8"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SP2vzzLUDd3-"
      },
      "source": [
        "## your code"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Building and compile the model\n",
        "\n",
        "Build your neural network logistic regression model, then compile it:"
      ],
      "metadata": {
        "id": "R_87G5N5qx3s"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9R3b8UT7D4fI"
      },
      "source": [
        "## your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question for you**: How many parameters does the model have? Why?"
      ],
      "metadata": {
        "id": "WgEvojiWrCXE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fit (train) the model"
      ],
      "metadata": {
        "id": "6xOvSSU3rLhd"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oyqSujucDnxF"
      },
      "source": [
        "## your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model evaluation\n",
        "\n",
        "Get predictions and evaluate the performance of the model:"
      ],
      "metadata": {
        "id": "fYF-PA02rgbZ"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-9pRZMKGUCg"
      },
      "source": [
        "## your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rhd1BGR6E9IY"
      },
      "source": [
        "#### On your own (super optional!)\n",
        "\n",
        "* to improve our understanding of logistic regression we could implement it from scratch, without using keras, following the [steps detailed here](https://towardsdatascience.com/a-logistic-regression-from-scratch-3824468b1f88) (but only if we are very brave)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## your code here"
      ],
      "metadata": {
        "id": "39xDsxlZYklU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}