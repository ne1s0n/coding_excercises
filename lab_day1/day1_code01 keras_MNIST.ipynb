{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tUy9M38H59ta"
      },
      "source": [
        "# A deep-learning neural network for image recognition\n",
        "We present here a `Python Keras` implementation of a deep learning neural network for image recognition.\n",
        "\n",
        "This is a high-level implementation with the code organised in blocks that resemble the main logical steps involved in developing a deep learning model.\n",
        "\n",
        "In the next session we'll se the detailed (lower level) implementation, to get a good peek at the code!\n",
        "\n",
        "The publicly available `MNIST` dataset is used.\n",
        "\n",
        "`Keras` is a popular `Python` library for deep learning models:\n",
        "- wrapper for `TensorFlow`\n",
        "- minimalistic\n",
        "- modular\n",
        "- easy to implement\n",
        "\n",
        "The `MNIST` database (Modified National Institute of Standards and Technology database) is a large database of hand-written digits (details and data [here](http://yann.lecun.com/exdb/mnist/)):\n",
        "\n",
        "![mnist](https://drive.google.com/uc?id=1KNK3-8qahQixvL-StpDAs6GoOUAHKSDy)\n",
        "\n",
        "Deep learning consists of neural networks with multiple hidden layers that learn increasingly abstract and complex representations of the input data.\n",
        "For instance, if we train a deep learning model to recognize hand-written digits (images):\n",
        "\n",
        "- the first hidden layers might only learn local edge patterns;\n",
        "- subsequent layers learns more complex representations of the data;\n",
        "- the last layer will classify the image as one of ten digits.\n",
        "\n",
        "For image recognition we use a specific deep learning architecture: **convolutional neural networks** (*CNN*), which assume that input data are images, thereby greatly reducing the number of model parameters to be tuned (more on *CNN's* later in the course).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EG18PhUOLMFk"
      },
      "source": [
        "## 1. SET UP\n",
        "\n",
        "- import libraries\n",
        "- set seed (for reproducibility)\n",
        "\n",
        "We use a `Python` script (`support_code.py`) that contains functions used to do these operations transparently for us (behind the scene)"
      ]
    },
    {
      "cell_type": "code",

      "execution_count": null,
      "metadata": {
        "id": "qkYYv-WU3lbG"
      },
      "outputs": [],

      "source": [
        "!wget -O support_code.py https://raw.githubusercontent.com/ne1s0n/coding_excercises/master/lab_day1/support_code.py\n",
        "%run support_code.py"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The next call to the `set_seeds()` function does two things:\n",
        "\n",
        "* set three random seeds (python, tensorflow and numpy)\n",
        "* make TensorFlow ops as deterministic as possible, at the cost of affecting the\n",
        "  overall performance"
      ],
      "metadata": {
        "id": "uyDuLh43rxkQ"
      }
    },
    {
      "cell_type": "code",

      "execution_count": null,

      "metadata": {
        "id": "_QNtsrFaVgR7"
      },
      "outputs": [],
      "source": [
        "n = 132\n",
        "set_seeds(n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OO1GZwrVdFgg"
      },
      "source": [
        "## 2. LOAD THE DATA: `load_data()`\n",
        "\n",
        "- choose how many training and test examples to load from the MNIST dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rG7RUXrA52gj"
      },
      "source": [
        "We load the data from the MNIST dataset, and assign them to the training and testing sets.\n",
        "\n",
        "Image data is generally harder to work with than flat relational data. The MNIST dataset is a beginner-friendly intoduction to working with image data: it contains $70\\,000$ labeled images of handwritten digits. These are grey-scale images, 28 x 28 pixels.\n",
        "\n",
        "The MNIST dataset comprises $60\\,000$ training observations and $10\\,000$ test observations: the function `load_data()` automatically assigns these to the training and testing sets."
      ]
    },
    {
      "cell_type": "code",

      "execution_count": null,

      "metadata": {
        "id": "Pwqk_z1svIDC"
      },
      "outputs": [],
      "source": [
        "ntrain = 20000\n",
        "ntest = 5000\n",
        "(X_train, y_train, X_test, y_test) = load_data(ntrain,ntest)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2vJ80YMTdhXk"
      },
      "source": [
        "A little sanity check"
      ]
    },
    {
      "cell_type": "code",

      "execution_count": null,
      "metadata": {
        "id": "3LyPp6hFvVlX"
      },
      "outputs": [],

      "source": [
        "print(\"Size of the training set\")\n",
        "print(X_train.shape)\n",
        "print(\"Size of the test set\")\n",
        "print(X_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgVK5wI4GetE"
      },
      "source": [
        "Data have been split into a **training** and a **testing set**, and within these into a **three-dimensional array** $X$ of **features** (samples x pixels x pixels) and a vector $y$ of labels (0-9 digits).\n",
        "\n",
        "Each record in the 3-D array $X$ is a 28 x 28 matrix of grayscale intensities (1 byte = 8 bits = 0 - 255 values). Grayscale (black-n-white) images only use one color channel. Colour images use three channels (e.g. RGB) and each image (record) is therefore a 3-D matrix (pixels x pixels x 3)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OGzaheMHeIk2"
      },
      "source": [
        "Let's have a look at one such image:"
      ]
    },
    {
      "cell_type": "code",

      "execution_count": null,
      "metadata": {
        "id": "uaLJe1Vn0lXI"
      },
      "outputs": [],

      "source": [
        "i = 2\n",
        "print(\"First training label: \",y_train[i])\n",
        "plt.imshow(X_train[i, :, :])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_o9JYptl9q5"
      },
      "source": [
        "By default the matplotlib function `imshow()` uses pseudocolors to plot grayscale images; if you want to display the actual grayscale image, you can specify the color mapping parameters:"
      ]
    },
    {
      "cell_type": "code",

      "execution_count": null,
      "metadata": {
        "id": "du5B0HEDl5ni"
      },
      "outputs": [],

      "source": [
        "plt.imshow(X_train[0], cmap='gray', vmin=0, vmax=255)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "What about the labels?"
      ],
      "metadata": {
        "id": "oXoM_zjzoqew"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_train[0:10]"
      ],
      "metadata": {

        "id": "exP6LIiZnmZo"
      },
      "execution_count": null,
      "outputs": []

    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MbGoAqrV55W5"
      },
      "source": [
        "## 3. CONFIGURE THE PARAMETERS: `set_parameters()`\n",
        "\n",
        "Define model parameters:\n",
        "\n",
        "- input shape\n",
        "- n. of classes: n. of classes to predict (10 digits, in the MNIST problem)\n",
        "- batch size: DL models typically do not process the entire dataset at once, rather break it in **batches**\n",
        "- n. of epochs: n. of **iterations** over the entire dataset"
      ]
    },
    {
      "cell_type": "code",

      "execution_count": null,

      "metadata": {
        "id": "wljzYJtfbxji"
      },
      "outputs": [],
      "source": [
        "(img_rows,img_cols,n_classes,batch_size,n_epochs) = set_parameters(28,28,10,64,20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_1i4lpSr9IbD"
      },
      "source": [
        "## 4. DATA PREPROCESSING: `preprocess()`\n",
        "\n",
        "- first, we need to explicitly declare the **depth of the image representation** array: in the case of grayscale images there is only one channel, and this dimension is 1\n",
        "- we then **convert the input data type to `float32`** and **normalize the data** values to the range $[0, 1]$. These are operational modifications necessary to speed up and optimize the calculations.\n",
        "- finally, **label vectors are converted to class matrices**. This serves to convert a vector of numerical digits to a matrix of ten classes per observation, which is a better suited representation for a classification problem."
      ]
    },
    {
      "cell_type": "code",

      "execution_count": null,
      "metadata": {
        "id": "Y0iC2KdoCyGv"
      },
      "outputs": [],

      "source": [
        "(X_train,X_test,y_train,y_test,input_shape) = preprocess(X_train,X_test,y_train,y_test,img_rows,img_cols,n_classes)"
      ]
    },
    {
      "cell_type": "code",

      "execution_count": null,
      "metadata": {
        "id": "IxFIiH5Pf4cX"
      },
      "outputs": [],

      "source": [
        "print(\"Modified array dimensions:\")\n",
        "print(X_train.shape)\n",
        "print(input_shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05kzgtxDgdpP"
      },
      "source": [
        "Let's take a look at the labels matrix (the 'answers'): the first four training examples(labels)"
      ]
    },
    {
      "cell_type": "code",

      "execution_count": null,
      "metadata": {
        "id": "8pg9tUjtQX2d"
      },
      "outputs": [],

      "source": [
        "print(y_train[0:4])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m8B_bBPVmgOK"
      },
      "source": [
        "**Your turn! QUESTION: which digits are these?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KlUJzLw46FvK"
      },
      "source": [
        "## 5. BUILD THE MODEL: `build_model()`\n",
        "\n",
        "We now define our deep-learning **neural network architecture**, and start building our model for image recognition.\n"
      ]
    },
    {
      "cell_type": "code",

      "execution_count": null,

      "metadata": {
        "id": "udCTMi2JWaY3"
      },
      "outputs": [],
      "source": [
        "model = build_model(input_shape, n_classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3UJeoYOshfHB"
      },
      "source": [
        "## 6. COMPILE THE MODEL: `compile_model()`\n",
        "\n",
        "The compilation is the final step in creating a model. Once the compilation is done, we can move on to training phase:\n",
        "\n",
        "- loss function (objective of the optimizer)\n",
        "- optimizer (core machinery used to find the weights of the model: learning)\n",
        "- metrics (used to evaluate the model)\n",
        "\n",
        "All this pieces are put together (+ the specified network architecture) in the model compilation step."
      ]
    },
    {
      "cell_type": "code",

      "execution_count": null,
      "metadata": {
        "id": "YReQveVpRVKg"
      },
      "outputs": [],

      "source": [
        "model = compile_model(model)"
      ]
    },
    {
      "cell_type": "code",

      "execution_count": null,
      "metadata": {
        "id": "d6NuAj6U0RFd"
      },
      "outputs": [],

      "source": [
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FKeXuJK86QCJ"
      },
      "source": [
        "## 7. TRAIN THE MODEL: `train_model()`\n",
        "\n",
        "We then fit the model on the training data, specifying:\n",
        "\n",
        "- the batch size\n",
        "- the number of epochs to train the model"
      ]
    },
    {
      "cell_type": "code",

      "execution_count": null,
      "metadata": {
        "id": "u0i35-QmSHav"
      },
      "outputs": [],

      "source": [
        "trained_model = train_model(model,X_train,y_train,batch_size,n_epochs,1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eGl-EKfQjwif"
      },
      "source": [
        "## 8. TEST THE MODEL: `evaluate_model()`\n",
        "\n",
        "We can now measure the performance (in terms of prediction accuracy) of the trained deep-learning model for image recognition.\n",
        "To measure the performance, we applied our trained model to independent test data."
      ]
    },
    {
      "cell_type": "code",

      "execution_count": null,
      "metadata": {
        "id": "1U3vgLaETLQI"
      },
      "outputs": [],

      "source": [
        "(score, confusion_matrix) = evaluate_model(trained_model, X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BN8i_Waij785"
      },
      "source": [
        "Let's look at the eaccuracy of the model:"
      ]
    },
    {
      "cell_type": "code",

      "execution_count": null,
      "metadata": {
        "id": "i_PUvRKga0WU"
      },
      "outputs": [],

      "source": [
        "print(round(score[1],4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AOaSAhBhkAQg"
      },
      "source": [
        "And the **confusion matrix**"
      ]
    },
    {
      "cell_type": "code",

      "execution_count": null,
      "metadata": {
        "id": "24oSLKTsUh5n"
      },
      "outputs": [],

      "source": [
        "print(confusion_matrix)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k3Rx5ww3ZfsO"
      },
      "source": [
        "### Confusion matrix\n",
        "\n",
        "A [confusion matrix](https://en.wikipedia.org/wiki/Confusion_matrix) is another way to express the accuracy of your predictions. It's a square matrix, with as many rows (and columns) as your classes. Rows represent *true values* and columns represent *predicted values*. On the main diagonal are thus reported the correct predictions, while off-diagonal elements represent errors.\n",
        "\n",
        "We use the [confusion_matrix()](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html) function part of [scikit-learn library](https://scikit-learn.org/stable/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FSFXg6obcHl4"
      },
      "source": [
        "**Your turn! QUESTION: Can you spot the most ambiguous, often confounded classes?**"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
