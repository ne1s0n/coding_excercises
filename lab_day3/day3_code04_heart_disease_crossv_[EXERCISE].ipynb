{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dCbL-3UsFO3l"
      },
      "source": [
        "# You are breaking my heart - exercises\n",
        "\n",
        "This dataset contains information on 303 patients. Several medically relevant data are available (age, sex, cholesterol, resting blood pressure...). Our task is to predict the presence of heart disease (column \"target\", 0 means healty, 1 means sick).\n",
        "\n",
        "This dataset is described in detail:\n",
        "\n",
        "* on Kaggle datasets: https://www.kaggle.com/ronitf/heart-disease-uci\n",
        "* on its original webpage: https://archive.ics.uci.edu/ml/datasets/Heart+Disease\n",
        "\n",
        "I've downloaded a copy of the data and made it available at the following url:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vKkpvbRpxMY7"
      },
      "source": [
        "DATASET_URL = 'https://raw.githubusercontent.com/ne1s0n/coding_excercises/master/data/datasets_33180_43520_heart.csv'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQLaXLYf0Fh6"
      },
      "source": [
        "# Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R90Prp_wAF-Z"
      },
      "source": [
        "import pandas\n",
        "\n",
        "#pandas can read a csv directly from a url\n",
        "heart_data = pandas.read_csv(DATASET_URL)\n",
        "print(heart_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oorqzi51Cjw3"
      },
      "source": [
        "#splitting features and target\n",
        "features = heart_data.iloc[:,:-1]\n",
        "target = heart_data.iloc[:,-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5KwlarWPInSz"
      },
      "source": [
        "#take a look at what we have done\n",
        "print(heart_data.columns)\n",
        "print(features.shape)\n",
        "print(target.shape) #beware of rank 1 arrays"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P2ISOT2GBg66"
      },
      "source": [
        "## Train and Validation sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BkudbVoiBmI4"
      },
      "source": [
        "#we want to have the same proportion of classes in both train and validation sets\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "\n",
        "#building a StratifiedShuffleSplit object (sss among friends) with 20% data\n",
        "#assigned to validation set (here called \"test\")\n",
        "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=0)\n",
        "\n",
        "#the .split() method returns (an iterable over) two lists which can be\n",
        "#used to index the samples that go into train and validation sets\n",
        "for train_index, val_index in sss.split(features, target):\n",
        "    features_train = features.iloc[train_index, :]\n",
        "    features_val   = features.iloc[val_index, :]\n",
        "    target_train   = target[train_index]\n",
        "    target_val     = target[val_index]\n",
        "\n",
        "#let's print some shapes to get an idea of the resulting data structure\n",
        "print(features_train.shape)\n",
        "print(features_val.shape)\n",
        "print(target_train.shape)\n",
        "print(target_val.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZoQ4goJyQKN2"
      },
      "source": [
        "# EXCERCISES!\n",
        "\n",
        "The previous code (`day3_code02 heart disease crossv.ipynb`) crossvalidated the effect of having different units in a single layer. We now want to explore the effect of using more than one layer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jCXxcix-RPgS"
      },
      "source": [
        "## Exercise 1: expand the network\n",
        "\n",
        "In the lesson, in section \"Improvement, better model\" we declared a simple, single-layer model. Let's do something bigger.\n",
        "\n",
        "**ASSIGNMENT**: you are required to declare a new model with two layers. The first layer will have 10 units, the second 5 units. There will also be the final, output layer, with sigmoid activation function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0E5SNrG4SBz7"
      },
      "source": [
        "######## OLD CODE ########\n",
        "#old code, copied here for your reference:\n",
        "\n",
        "if False:\n",
        "  from keras.models import Sequential\n",
        "  from keras.layers import Dense\n",
        "\n",
        "  # 2-class logistic regression in Keras\n",
        "  model = Sequential()\n",
        "  model.add(Dense(10, activation='relu', input_dim=features_train.shape[1]))\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "######## YOUR CODE HERE ########\n",
        "\n",
        "################################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tiYhJkDzTShH"
      },
      "source": [
        "You have now defined the architecture. Let's take a look at it.\n",
        "\n",
        "**ASSIGNMENT** invoke the [.summary()](https://keras.io/api/models/model/#summary-method) built-in method of your model object. Verify that the resulting network has 201 trainable parameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i46JLPaZT_wT"
      },
      "source": [
        "######## YOUR CODE HERE ########\n",
        "\n",
        "################################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VoOFqH_cVcBC"
      },
      "source": [
        "## Excercise 2: expand the network, programmatically\n",
        "\n",
        "We are preparing the terrain to do a proper grid-search crossvalidation. This means we aim to investigate the effect of combining a different number of layers and of units per layer. To do so we need a function that, give the number of hidden layers and the number of units per layer, returns a compiled model of the required topography.\n",
        "\n",
        "**ASSIGNMENT** define a function `build_model` with three input parameters: `n_layers`, `n_units`, `input_size`. The function internally will declare a sequential model of the required shape. ATTENTION: the first layer needs special treatment.\n",
        "\n",
        "NOTE: Keep in mind the difference between hidden and total layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vekmpt0oYFfq"
      },
      "source": [
        "######## YOUR CODE HERE ########\n",
        "\n",
        "################################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-Zb06VhaTMh"
      },
      "source": [
        "Let's use the funtion you just declared.\n",
        "\n",
        "**ASSIGNMENT**: invoke `build_model` with the following parameters:\n",
        "\n",
        "- `n_layers` = 2\n",
        "- `n_units` = 5\n",
        "- `input_size` = features_train.shape[1]\n",
        "\n",
        "Verify that the resulting number of trainable parameters is 106."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8VGbLknGa5MZ"
      },
      "source": [
        "######## YOUR CODE HERE ########\n",
        "model2 = build_model(n_layers=2, n_units=5, input_size=features_train.shape[1])\n",
        "model2.summary()\n",
        "################################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7PI5okz5bEcE"
      },
      "source": [
        "## Excercise 3: explore the hyperparameters\n",
        "\n",
        "We want to explore the effects of having a different number of layers and of units per layer. In particular we want to investigate:\n",
        "\n",
        "* number of layers: 1 (as done above, not counting the output layer), 2, 3\n",
        "* number of units per layer: 2, 4\n",
        "\n",
        "This brings to a total of 6 combinations.\n",
        "\n",
        "**ASSIGNMENT**: write a loop that, for each combination of layers and units, trains a network on the available feature and validation sets. Inside the loop, once the model is trained, print the train and validation losses.\n",
        "\n",
        "For compilation/training, use the following:\n",
        "\n",
        "* optimizer: rmsprop\n",
        "* loss: binary_crossentropy\n",
        "* epochs: 20\n",
        "* verbose=0 (or not, you decide)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6cXfVr6cYqg7"
      },
      "source": [
        "#we want to study the combination of these parameters\n",
        "layers_list = [1, 2, 3]\n",
        "units_list = [2, 4]\n",
        "\n",
        "#remember that the datasets have already been declared:\n",
        "# - features_train\n",
        "# - features_val\n",
        "# - target_train\n",
        "# - target_val\n",
        "\n",
        "######## YOUR CODE HERE ########\n",
        "#a double loop to explore the parameters\n",
        "\n",
        "################################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KyadsbtX1OQ7"
      },
      "source": [
        "## Exercise 4: a proper crossvalidation\n",
        "\n",
        "It's now time to do a proper crossvalidation over our train dataset. For this exercise we ignore the old validation dataset (`features_val`, `target_val`) that could be used as a TEST set.\n",
        "\n",
        "Our training set (`features_train`, `target_train`) needs to be sliced in five parts (i.e., folds). We'll then:\n",
        "\n",
        "* use the folds number 1, 2, 3, and 4 for training, fold number 5 for validation\n",
        "* use the folds number 1, 2, 3, and 5 for training, fold number 4 for validation\n",
        "* use the folds number 1, 2, 4, and 5 for training, fold number 3 for validation\n",
        "* and so forth\n",
        "\n",
        "To slice the dataset we'll use the [StratifiedKFold class](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html) from `sklearn.model_selection` subpackage. We used the same object in the lesson, so feel free to refer to that code for reference. As a reminder, to use it porperly you'll need to:\n",
        "\n",
        "* import the class\n",
        "* declare a StratifiedKFold object telling the constructor how many folds (`n_splits`) you want\n",
        "* loop over folds via the `.split()` method, which requires the data (features and target) as input and returns the indices of the current split\n",
        "\n",
        "**ASSIGNMENT** modify the loop you wrote in the previous exercise so that the model is trained 5 times on different splits of (`features_train`, `target_train`). Print the loss and val_loss averaged over the folds.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XX7Y-E3q1P2s"
      },
      "source": [
        "######## YOUR CODE HERE ########\n",
        "\n",
        "################################"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}