{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Effects of Learning Rate (and maybe a little overfitting)\n",
        "\n",
        "- breast cancer example\n",
        "- three identical nets, different LR, side by side comparison"
      ],
      "metadata": {
        "id": "m-bk4DL_WVRx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup(s)"
      ],
      "metadata": {
        "id": "bKE0Xq6M79co"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Libraries setup"
      ],
      "metadata": {
        "id": "J18SWcB0WnLg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#very common libraries, that we for sure are using\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "qrRIdp56WpET"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Seed setup"
      ],
      "metadata": {
        "id": "Rc1kzLhAhC73"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy.random import seed\n",
        "myseed = 0\n",
        "seed(myseed)\n",
        "#tf.random.set_seed(myseed)\n",
        "tf.keras.utils.set_random_seed(myseed)"
      ],
      "metadata": {
        "id": "krBiyWMihEnp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data setup"
      ],
      "metadata": {
        "id": "YxGmXCFNWhu9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lQJoQjGZWHY0"
      },
      "outputs": [],
      "source": [
        "#libraries for this block\n",
        "import sklearn.datasets\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "\n",
        "# loading data\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "bcancer = load_breast_cancer()\n",
        "y = bcancer.target\n",
        "X = pd.DataFrame(bcancer.data, columns=bcancer.feature_names)\n",
        "\n",
        "# normalizing\n",
        "X = (X - X.mean())/X.std()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Support functions"
      ],
      "metadata": {
        "id": "1GpC08GkYSRk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#libraries for this block\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "\n",
        "# a function to declare and train the network, given the learning rate\n",
        "def train_net(X, y, LR,\n",
        "              output_activation = 'sigmoid',\n",
        "              loss_function = 'binary_crossentropy',\n",
        "              extra_metrics = ['binary_accuracy'],\n",
        "              num_epochs = 100):\n",
        "\n",
        "  #this depends on the input data\n",
        "  input_shape = (X.shape[1],)\n",
        "\n",
        "  # 1-node logistic neural network\n",
        "  model_1LN = Sequential()\n",
        "  model_1LN.add(Dense(1, activation=output_activation))\n",
        "\n",
        "  #instantiating the optimizer, compiling, training\n",
        "  opt = SGD(learning_rate=LR)\n",
        "  model_1LN.compile(optimizer=opt, loss=loss_function, metrics=extra_metrics)\n",
        "  history = model_1LN.fit(X, y, epochs=num_epochs, validation_split=0.2, verbose=0)\n",
        "\n",
        "  return(history)\n",
        "\n",
        "#a function to plot loss or metrics\n",
        "def plot_history(h, title, target='loss'):\n",
        "    plt.rcParams[\"figure.figsize\"]=5,5\n",
        "    plt.plot(h.history[target], label = \"Train \" + target)\n",
        "    plt.plot(h.history['val_'+target], label = \"Validation \" + target)\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.title(title)\n",
        "    plt.legend()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "TwCuMpmWfLCK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Compare various LR"
      ],
      "metadata": {
        "id": "V9mKVNothdZm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#considered values\n",
        "LR_small  = 0.00001\n",
        "LR_medium = 0.01\n",
        "LR_large  = 10\n",
        "\n",
        "#let's train the net\n",
        "h_small  = train_net(X=X, y=y, LR=LR_small)\n",
        "h_medium = train_net(X=X, y=y, LR=LR_medium)\n",
        "h_large  = train_net(X=X, y=y, LR=LR_large)"
      ],
      "metadata": {
        "id": "fYJ045XKhhtX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_history(h_small, title = 'LR =' + str(LR_small))\n",
        "plot_history(h_medium, title = 'LR =' + str(LR_medium))\n",
        "plot_history(h_large, title = 'LR =' + str(LR_large))"
      ],
      "metadata": {
        "id": "97EtnmaDiKvL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Side by side plot for better comparison"
      ],
      "metadata": {
        "id": "PS_aYQfXBwDk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# building a single dataframe\n",
        "\n",
        "#small LR\n",
        "hist = pd.DataFrame({\n",
        "    'epoch' : [i for i in range(100)],\n",
        "    'variable' : 'loss',\n",
        "    'value' : h_small.history['loss'],\n",
        "    'LR' : LR_small\n",
        "    })\n",
        "hist = pd.concat([hist, pd.DataFrame({\n",
        "    'epoch' : [i for i in range(100)],\n",
        "    'variable' : 'val_loss',\n",
        "    'value' : h_small.history['val_loss'],\n",
        "    'LR' : LR_small\n",
        "    })], ignore_index=True)\n",
        "\n",
        "#medium LR\n",
        "hist = pd.concat([hist, pd.DataFrame({\n",
        "    'epoch' : [i for i in range(100)],\n",
        "    'variable' : 'loss',\n",
        "    'value' : h_medium.history['loss'],\n",
        "    'LR' : LR_medium\n",
        "    })], ignore_index=True)\n",
        "hist = pd.concat([hist, pd.DataFrame({\n",
        "    'epoch' : [i for i in range(100)],\n",
        "    'variable' : 'val_loss',\n",
        "    'value' : h_medium.history['val_loss'],\n",
        "    'LR' : LR_medium\n",
        "    })], ignore_index=True)\n",
        "\n",
        "#large LR\n",
        "hist = pd.concat([hist, pd.DataFrame({\n",
        "    'epoch' : [i for i in range(100)],\n",
        "    'variable' : 'loss',\n",
        "    'value' : h_large.history['loss'],\n",
        "    'LR' : LR_large\n",
        "    })], ignore_index=True)\n",
        "hist = pd.concat([hist, pd.DataFrame({\n",
        "    'epoch' : [i for i in range(100)],\n",
        "    'variable' : 'val_loss',\n",
        "    'value' : h_large.history['val_loss'],\n",
        "    'LR' : LR_large\n",
        "    })], ignore_index=True)"
      ],
      "metadata": {
        "id": "GeqRjOMp4NcU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A little check on our data"
      ],
      "metadata": {
        "id": "1MFmq9t79gdq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hist.head"
      ],
      "metadata": {
        "id": "VRNMLFmD9iBp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The actual plot"
      ],
      "metadata": {
        "id": "nszVXr4BB1is"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "\n",
        "#a three-paneled plot\n",
        "g = sns.FacetGrid(data=hist, col='LR', hue='variable', col_wrap=3, height=5)\n",
        "g.map(sns.lineplot, 'epoch', 'value')\n",
        "g.add_legend()"
      ],
      "metadata": {
        "id": "SgVdqVOJ6tF_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Further readings: automatic LR tuning\n",
        "\n",
        "No algorithm can optimize LR for every use-case. It is however possible to have a systematic approach in the exploration of LR values. A very good starting point is pyimagesearch's cycle of posts on the topic, and in particular [Part #3: Keras Learning Rate Finder](https://pyimagesearch.com/2019/08/05/keras-learning-rate-finder/)"
      ],
      "metadata": {
        "id": "oOqcpQnTB4yx"
      }
    }
  ]
}