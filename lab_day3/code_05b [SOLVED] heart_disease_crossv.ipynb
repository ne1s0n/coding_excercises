{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"code_05b [SOLVED] heart_disease_crossv.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"dCbL-3UsFO3l"},"source":["# You are breaking my heart - exercises\n","\n","This dataset contains information on 303 patients. Several medically relevant data are available (age, sex, cholesterol, resting blood pressure...). Our task is to predict the presence of heart disease (column \"target\", 0 means healty, 1 means sick).\n","\n","This dataset is described in detail:\n","\n","* on Kaggle datasets: https://www.kaggle.com/ronitf/heart-disease-uci\n","* on its original webpage: https://archive.ics.uci.edu/ml/datasets/Heart+Disease\n","\n","I've downloaded a copy of the data and made it available at the following url:"]},{"cell_type":"code","metadata":{"id":"vKkpvbRpxMY7","executionInfo":{"status":"ok","timestamp":1601279670377,"user_tz":-120,"elapsed":1161,"user":{"displayName":"Nelson Nazzicari","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgArOt61KuUpm4iKPq7j-oDcGINWQeMziaxc5Fy3Q=s64","userId":"06091096357258353861"}}},"source":["DATASET_URL = 'https://raw.githubusercontent.com/ne1s0n/coding_excercises/master/data/datasets_33180_43520_heart.csv'"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wQLaXLYf0Fh6"},"source":["# Data"]},{"cell_type":"code","metadata":{"id":"R90Prp_wAF-Z","executionInfo":{"status":"ok","timestamp":1601279671108,"user_tz":-120,"elapsed":1871,"user":{"displayName":"Nelson Nazzicari","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgArOt61KuUpm4iKPq7j-oDcGINWQeMziaxc5Fy3Q=s64","userId":"06091096357258353861"}},"outputId":"69b71c0e-9e37-4234-8c4e-5a5281d1e166","colab":{"base_uri":"https://localhost:8080/","height":260}},"source":["import pandas\n","\n","#pandas can read a csv directly from a url\n","heart_data = pandas.read_csv(DATASET_URL)\n","print(heart_data)"],"execution_count":2,"outputs":[{"output_type":"stream","text":["     age  sex  cp  trestbps  chol  fbs  ...  exang  oldpeak  slope  ca  thal  target\n","0     63    1   3       145   233    1  ...      0      2.3      0   0     1       1\n","1     37    1   2       130   250    0  ...      0      3.5      0   0     2       1\n","2     41    0   1       130   204    0  ...      0      1.4      2   0     2       1\n","3     56    1   1       120   236    0  ...      0      0.8      2   0     2       1\n","4     57    0   0       120   354    0  ...      1      0.6      2   0     2       1\n","..   ...  ...  ..       ...   ...  ...  ...    ...      ...    ...  ..   ...     ...\n","298   57    0   0       140   241    0  ...      1      0.2      1   0     3       0\n","299   45    1   3       110   264    0  ...      0      1.2      1   0     3       0\n","300   68    1   0       144   193    1  ...      0      3.4      1   2     3       0\n","301   57    1   0       130   131    0  ...      1      1.2      1   1     3       0\n","302   57    0   1       130   236    0  ...      0      0.0      1   1     2       0\n","\n","[303 rows x 14 columns]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Oorqzi51Cjw3","executionInfo":{"status":"ok","timestamp":1601279671117,"user_tz":-120,"elapsed":1872,"user":{"displayName":"Nelson Nazzicari","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgArOt61KuUpm4iKPq7j-oDcGINWQeMziaxc5Fy3Q=s64","userId":"06091096357258353861"}}},"source":["#splitting features and target\n","features = heart_data.iloc[:,:-1]\n","target = heart_data.iloc[:,-1]"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"5KwlarWPInSz","executionInfo":{"status":"ok","timestamp":1601279671121,"user_tz":-120,"elapsed":1865,"user":{"displayName":"Nelson Nazzicari","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgArOt61KuUpm4iKPq7j-oDcGINWQeMziaxc5Fy3Q=s64","userId":"06091096357258353861"}},"outputId":"b8aa595c-bf7a-4b8f-a00a-432a9163969b","colab":{"base_uri":"https://localhost:8080/","height":104}},"source":["#take a look at what we have done\n","print(heart_data.columns)\n","print(features.shape)\n","print(target.shape) #beware of rank 1 arrays"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Index(['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach',\n","       'exang', 'oldpeak', 'slope', 'ca', 'thal', 'target'],\n","      dtype='object')\n","(303, 13)\n","(303,)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"P2ISOT2GBg66"},"source":["## Train and Validation sets"]},{"cell_type":"code","metadata":{"id":"BkudbVoiBmI4","executionInfo":{"status":"ok","timestamp":1601279671482,"user_tz":-120,"elapsed":2216,"user":{"displayName":"Nelson Nazzicari","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgArOt61KuUpm4iKPq7j-oDcGINWQeMziaxc5Fy3Q=s64","userId":"06091096357258353861"}},"outputId":"011b2727-e6e3-4db8-9256-3fd4402334e6","colab":{"base_uri":"https://localhost:8080/","height":86}},"source":["#we want to have the same proportion of classes in both train and validation sets\n","from sklearn.model_selection import StratifiedShuffleSplit\n","\n","#building a StratifiedShuffleSplit object (sss among friends) with 20% data\n","#assigned to validation set (here called \"test\")\n","sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=0)\n","\n","#the .split() method returns (an iterable over) two lists which can be\n","#used to index the samples that go into train and validation sets\n","for train_index, val_index in sss.split(features, target):\n","    features_train = features.iloc[train_index, :]\n","    features_val   = features.iloc[val_index, :]\n","    target_train   = target[train_index]\n","    target_val     = target[val_index]\n","    \n","#let's print some shapes to get an idea of the resulting data structure\n","print(features_train.shape)\n","print(features_val.shape)\n","print(target_train.shape)\n","print(target_val.shape)"],"execution_count":5,"outputs":[{"output_type":"stream","text":["(242, 13)\n","(61, 13)\n","(242,)\n","(61,)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ZoQ4goJyQKN2"},"source":["# EXCERCISES!\n","\n","The code above crossvalidated the effect of having different units in a single layer. We now want to explore the effect of using more than one layer."]},{"cell_type":"markdown","metadata":{"id":"jCXxcix-RPgS"},"source":["## Exercise 1: expand the network\n","\n","In the lesson, in section \"Improvement, better model\" we declared a simple, single-layer model. Let's do something bigger.\n","\n","**ASSIGNMENT**: you are required to declare a new model with two layers. The first layer will have 10 units, the second 5 units. There will also be the final, output layer, with sigmoid activation function."]},{"cell_type":"code","metadata":{"id":"0E5SNrG4SBz7","executionInfo":{"status":"ok","timestamp":1601279678895,"user_tz":-120,"elapsed":9623,"user":{"displayName":"Nelson Nazzicari","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgArOt61KuUpm4iKPq7j-oDcGINWQeMziaxc5Fy3Q=s64","userId":"06091096357258353861"}}},"source":["######## OLD CODE ########\n","#old code, put here for your reference:\n","\n","if False:\n","  from keras.models import Sequential\n","  from keras.layers import Dense\n","\n","  # 2-class logistic regression in Keras\n","  model2 = Sequential()\n","  model2.add(Dense(10, activation='relu', input_dim=features_train.shape[1]))\n","  model2.add(Dense(1, activation='sigmoid'))\n","\n","######## YOUR CODE HERE ########\n","from keras.models import Sequential\n","from keras.layers import Dense\n","\n","model4 = Sequential()\n","model4.add(Dense(10, activation='relu', input_dim=features_train.shape[1]))\n","model4.add(Dense(5, activation='relu'))\n","model4.add(Dense(1, activation='sigmoid'))\n","################################"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tiYhJkDzTShH"},"source":["You have now defined the architecture. Let's take a look at it.\n","\n","**ASSIGNMENT** invoke the [.summary()](https://keras.io/api/models/model/#summary-method) built-in method of your model object. Verify that the resulting network has 201 trainable parameters."]},{"cell_type":"code","metadata":{"id":"i46JLPaZT_wT","executionInfo":{"status":"ok","timestamp":1601279678904,"user_tz":-120,"elapsed":9617,"user":{"displayName":"Nelson Nazzicari","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgArOt61KuUpm4iKPq7j-oDcGINWQeMziaxc5Fy3Q=s64","userId":"06091096357258353861"}},"outputId":"5c2ef12d-ff9c-48ac-80bd-31c6e63fd267","colab":{"base_uri":"https://localhost:8080/","height":260}},"source":["######## YOUR CODE HERE ########\n","model4.summary()\n","################################"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense (Dense)                (None, 10)                140       \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 5)                 55        \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 1)                 6         \n","=================================================================\n","Total params: 201\n","Trainable params: 201\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"VoOFqH_cVcBC"},"source":["## Excercise 2: expand the network, programmatically\n","\n","We are preparing the terrain to do a proper grid-search crossvalidation. This means we aim to investigate the effect of combining a different number of layers and of units per layer. To do so we need a function that, give the number of hidden layers and the number of units per layer, returns a compiled model of the required topography.\n","\n","**ASSIGNMENT** define a function `build_model` with three input parameters: `n_layers`, `n_units`, `input_size`. The function internally will declare a sequential model of the required shape. ATTENTION: the first layer needs special treatment."]},{"cell_type":"code","metadata":{"id":"vekmpt0oYFfq","executionInfo":{"status":"ok","timestamp":1601279678908,"user_tz":-120,"elapsed":9617,"user":{"displayName":"Nelson Nazzicari","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgArOt61KuUpm4iKPq7j-oDcGINWQeMziaxc5Fy3Q=s64","userId":"06091096357258353861"}}},"source":["######## YOUR CODE HERE ########\n","def build_model(n_layers, n_units, input_size):\n","  #declaring a local model\n","  m = Sequential()\n","\n","  #a loop that goes l=0, l=1, l=2, ..., l=(n_layers-1)\n","  for l in range(n_layers):\n","    #are we doing the first layer? if yes the declaration has an extra param\n","    if l == 0:\n","      m.add(Dense(units = n_units, activation='relu', input_dim=input_size))\n","    else:\n","      m.add(Dense(units = n_units, activation='relu'))\n","\n","  #adding the output layer\n","  m.add(Dense(1, activation='sigmoid'))\n","  \n","  #returning the declared model\n","  return(m)\n","################################"],"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Y-Zb06VhaTMh"},"source":["Let's use the funtion you just declared.\n","\n","**ASSIGNMENT**: invoke `build_model` with the following parameters:\n","\n","- `n_layers` = 2\n","- `n_units` = 5\n","- `input_size` = features_train.shape[1]\n","\n","Verify that the resulting number of trainable parameters is 106."]},{"cell_type":"code","metadata":{"id":"8VGbLknGa5MZ","executionInfo":{"status":"ok","timestamp":1601279678911,"user_tz":-120,"elapsed":9606,"user":{"displayName":"Nelson Nazzicari","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgArOt61KuUpm4iKPq7j-oDcGINWQeMziaxc5Fy3Q=s64","userId":"06091096357258353861"}},"outputId":"1a1ae69a-a7e4-47bd-9c96-3841c455868b","colab":{"base_uri":"https://localhost:8080/","height":260}},"source":["######## YOUR CODE HERE ########\n","build_model(2, 5, features_train.shape[1]).summary()\n","################################"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_3 (Dense)              (None, 5)                 70        \n","_________________________________________________________________\n","dense_4 (Dense)              (None, 5)                 30        \n","_________________________________________________________________\n","dense_5 (Dense)              (None, 1)                 6         \n","=================================================================\n","Total params: 106\n","Trainable params: 106\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"7PI5okz5bEcE"},"source":["## Excercise 3: explore the hyperparameters\n","\n","We want to explore the effects of having a different number of layers and of units per layer. In particular we want to investigate:\n","\n","* number of layers: 1 (as done above, not counting the output layer), 2, 3\n","* number of units per layer: 2, 4\n","\n","This brings to a total of 6 combinations.\n","\n","**ASSIGNMENT**: write a loop that, for each combination of layers and units, trains a network on the available feature and validation sets. Inside the loop, once the model is trained, print the train and validation losses.\n","\n","For compilation/training, use the following:\n","\n","* optimizer: rmsprop\n","* loss: binary_crossentropy\n","* epochs: 20\n","* verbose=0 (or not, you decide)"]},{"cell_type":"code","metadata":{"id":"6cXfVr6cYqg7","executionInfo":{"status":"ok","timestamp":1601279689715,"user_tz":-120,"elapsed":20397,"user":{"displayName":"Nelson Nazzicari","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgArOt61KuUpm4iKPq7j-oDcGINWQeMziaxc5Fy3Q=s64","userId":"06091096357258353861"}},"outputId":"822a0f1e-d1a4-48d7-db8a-d9ca8faabb0b","colab":{"base_uri":"https://localhost:8080/","height":330}},"source":["#we want to study the combination of these parameters\n","layers_list = [1, 2, 3]\n","units_list = [2, 4]\n","\n","#remember that the datasets have already been declared:\n","# - features_train\n","# - features_val\n","# - target_train\n","# - target_val\n","\n","######## YOUR CODE HERE ########\n","#a double loop to explore the parameters\n","for layers in layers_list:\n","  for units in units_list:\n","    #a little user interface\n","    print('Doing layers:' + str(layers) + ' units:', str(units))\n","\n","    #getting the model\n","    m = build_model(layers, units, features_train.shape[1])\n","\n","    #compiling\n","    m.compile(optimizer='rmsprop', loss='binary_crossentropy')\n","    \n","    #fitting\n","    history = m.fit(\n","        features_train, target_train, \n","        epochs=20, \n","        validation_data=(features_val, target_val), verbose=0)\n","    \n","    #let's just print the final loss\n","    print(' - train loss     : ' + str(history.history['loss'][-1]))\n","    print(' - validation loss: ' + str(history.history['val_loss'][-1]))\n","################################"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Doing layers:1 units: 2\n"," - train loss     : 0.6908085942268372\n"," - validation loss: 0.6910037398338318\n","Doing layers:1 units: 4\n"," - train loss     : 6.628240585327148\n"," - validation loss: 6.547569274902344\n","Doing layers:2 units: 2\n"," - train loss     : 0.6909536123275757\n"," - validation loss: 0.6911321878433228\n","Doing layers:2 units: 4\n"," - train loss     : 0.693126916885376\n"," - validation loss: 0.6511917114257812\n","Doing layers:3 units: 2\n"," - train loss     : 1.6838568449020386\n"," - validation loss: 1.473851203918457\n","Doing layers:3 units: 4\n"," - train loss     : 0.7067516446113586\n"," - validation loss: 0.5840612649917603\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"2ly1PkY5tzhp"},"source":["## Exercise 4: a proper crossvalidation\n","\n","It's now time to do a proper crossvalidation over our train dataset. For this exercise we ignore the old validation dataset (`features_val`, `target_val`) that could be used as a TEST set.\n","\n","Our training set (`features_train`, `target_train`) needs to be sliced in five parts (i.e., folds). We'll then:\n","\n","* use the folds number 1, 2, 3, and 4 for training, fold number 5 for validation\n","* use the folds number 1, 2, 3, and 5 for training, fold number 4 for validation\n","* use the folds number 1, 2, 4, and 5 for training, fold number 3 for validation\n","* and so forth\n","\n","To slice the dataset we'll use the [StratifiedKFold class](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html) from `sklearn.model_selection` subpackage. We used the same object in the lesson, so feel free to refer to that code for reference. As a reminder, to use it porperly you'll need to:\n","\n","* import the class\n","* declare a StratifiedKFold object telling the constructor how many folds (`n_splits`) you want\n","* loop over folds via the `.split()` method, which requires the data (features and target) as input and returns the indices of the current split\n","\n","**ASSIGNMENT** modify the loop you wrote in the previous exercise so that the model is trained 5 times on different splits of (`features_train`, `target_train`). Print the loss and val_loss averaged over the folds.\n"]},{"cell_type":"code","metadata":{"id":"KPD0WjsjuzMC","executionInfo":{"status":"ok","timestamp":1601281667777,"user_tz":-120,"elapsed":29364,"user":{"displayName":"Nelson Nazzicari","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgArOt61KuUpm4iKPq7j-oDcGINWQeMziaxc5Fy3Q=s64","userId":"06091096357258353861"}},"outputId":"d8fa9bbf-5430-4305-8f77-449bd239975e","colab":{"base_uri":"https://localhost:8080/","height":851}},"source":["######## YOUR CODE HERE ########\n","from sklearn.model_selection import StratifiedKFold\n","\n","#same code as exercise 3, up to a point.\n","\n","#a double loop to explore the parameters\n","for layers in layers_list:\n","  for units in units_list:\n","    #a little user interface\n","    print('Layers:' + str(layers) + ' units:', str(units))\n","\n","    #getting the model\n","    m = build_model(layers, units, features_train.shape[1])\n","\n","    #compiling\n","    m.compile(optimizer='rmsprop', loss='binary_crossentropy')\n","    \n","    #we'll put the losses for the five folds in these two container\n","    folds_loss = []\n","    folds_val_loss = []\n","\n","    #a counter for the folds, useful for keeping track of what's going on\n","    f = 0\n","\n","    #declaring the splitter\n","    skf = StratifiedKFold(n_splits = 5)\n","\n","    #loop over folds\n","    for train_index_cv, val_index_cv in skf.split(features_train, target_train):\n","      #informing the user\n","      f += 1\n","      print('- fold: ' + str(f))\n","\n","      #extracting the data for this fold\n","      features_train_cv = features_train.iloc[train_index_cv, :]\n","      features_val_cv   = features_train.iloc[val_index_cv, :]\n","      target_train_cv   = target_train.iloc[train_index_cv]\n","      target_val_cv     = target_train.iloc[val_index_cv]\n","\n","      #fitting\n","      history = m.fit(\n","          features_train_cv, target_train_cv, \n","          epochs=20, \n","          validation_data=(features_val_cv, target_val_cv), verbose=0)\n","    \n","      #we just store the losses at the last epoch\n","      folds_loss.append(history.history['loss'][-1])\n","      folds_val_loss.append(history.history['val_loss'][-1])\n","    \n","    #we have finished the folds, it's time to print the averaged results\n","    print(' - train loss     : ' + str(sum(folds_loss) / len(folds_loss)))\n","    print(' - validation loss: ' + str(sum(folds_val_loss) / len(folds_val_loss)))\n","################################\n"],"execution_count":15,"outputs":[{"output_type":"stream","text":["Layers:1 units: 2\n","- fold: 1\n","- fold: 2\n","- fold: 3\n","- fold: 4\n","- fold: 5\n"," - train loss     : 1.7836564779281616\n"," - validation loss: 1.7460849404335022\n","Layers:1 units: 4\n","- fold: 1\n","- fold: 2\n","- fold: 3\n","- fold: 4\n","- fold: 5\n"," - train loss     : 1.7561102509498596\n"," - validation loss: 1.2965580701828003\n","Layers:2 units: 2\n","- fold: 1\n","- fold: 2\n","- fold: 3\n","- fold: 4\n","- fold: 5\n"," - train loss     : 0.6908377051353455\n"," - validation loss: 0.690997838973999\n","Layers:2 units: 4\n","- fold: 1\n","- fold: 2\n","- fold: 3\n","- fold: 4\n","- fold: 5\n"," - train loss     : 0.810384726524353\n"," - validation loss: 0.769555139541626\n","Layers:3 units: 2\n","- fold: 1\n","- fold: 2\n","- fold: 3\n","- fold: 4\n","- fold: 5\n"," - train loss     : 0.6429208397865296\n"," - validation loss: 0.6381661653518677\n","Layers:3 units: 4\n","- fold: 1\n","- fold: 2\n","- fold: 3\n","- fold: 4\n","- fold: 5\n"," - train loss     : 0.6670983672142029\n"," - validation loss: 0.7045563697814942\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"hdVvXGm5ze0a"},"source":[""],"execution_count":null,"outputs":[]}]}